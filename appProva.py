import streamlit as st
import pandas as pd
import numpy as np
import warnings
import io
import time
from datetime import datetime
import matplotlib
matplotlib.use('Agg') # Backend n√£o-interativo para Matplotlib
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import RFECV
from sklearn.decomposition import PCA

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report, f1_score, precision_score, recall_score, accuracy_score
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score
import shap

MODO_PESQUISA = False

FEATURES_PRE_SELECIONADAS = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents', 'credit_to_duration_ratio', 'credit_to_age_ratio', 'checking_status_<0', 'checking_status_>=200', 'checking_status_no checking', 'credit_history_critical/other existing credit', 'credit_history_delayed previously', 'credit_history_existing paid', 'credit_history_no credits/all paid', 'purpose_education', 'purpose_furniture/equipment', 'purpose_new car', 'purpose_radio/tv', 'purpose_used car', 'savings_status_<100', 'savings_status_>=1000', 'savings_status_no known savings', 'employment_4<=X<7', 'employment_<1', 'employment_>=7', 'employment_unemployed', 'personal_status_male mar/wid', 'personal_status_male single', 'other_parties_guarantor', 'other_parties_none', 'property_magnitude_life insurance', 'property_magnitude_no known property', 'property_magnitude_real estate', 'other_payment_plans_none', 'housing_own', 'housing_rent', 'job_skilled', 'job_unskilled resident', 'own_telephone_yes', 'foreign_worker_yes']

# --- Configura√ß√£o da P√°gina e do Projeto ---

st.set_page_config(
    page_title="Plataforma de Risco de Cr√©dito",
    page_icon="üí≥",
    layout="wide",
    initial_sidebar_state="expanded"
)

class ProjectConfig:
    """
    Classe de configura√ß√£o para centralizar par√¢metros e constantes do projeto.
    Isso garante consist√™ncia e facilita a manuten√ß√£o do c√≥digo.
    """
    TARGET_VARIABLE = 'class'
    TEST_SIZE_RATIO = 0.3
    RANDOM_STATE_SEED = 42
    N_SPLITS_KFOLD = 5
    RFE_CV_SCORING = 'roc_auc'
    
    # Paleta de cores profissional para os gr√°ficos
    PRIMARY_COLOR = "#005f73"
    SECONDARY_COLOR = "#0a9396"
    ACCENT_COLOR = "#ee9b00"
    BAD_RISK_COLOR = "#ae2012"
    GOOD_RISK_COLOR = "#94d2bd"
    BACKGROUND_COLOR = "#F0F2F6" 
    TEXT_COLOR = "#001219"
    GRID_COLOR = "#e9d8a6"

    @staticmethod
    def get_plotly_template():
        """
        Define um template customizado para os gr√°ficos do Plotly.
        """
        template = go.layout.Template()
        template.layout.paper_bgcolor = ProjectConfig.BACKGROUND_COLOR
        template.layout.plot_bgcolor = ProjectConfig.BACKGROUND_COLOR
        template.layout.font = dict(color=ProjectConfig.TEXT_COLOR, family="Segoe UI")
        template.layout.xaxis = dict(gridcolor=ProjectConfig.GRID_COLOR, showgrid=True, zeroline=False)
        template.layout.yaxis = dict(gridcolor=ProjectConfig.GRID_COLOR, showgrid=True, zeroline=False)
        template.layout.title = dict(x=0.5, font=dict(size=20))
        return template

def initialize_session_state():
    """
    Inicializa o estado da sess√£o do Streamlit. Isso √© crucial para
    manter os dados e o progresso do usu√°rio entre as intera√ß√µes, criando
    uma experi√™ncia de aplica√ß√£o fluida em vez de um script que re-executa do zero.
    """
    session_state_defaults = {
        'app_stage': 'initialization',
        'data_loaded': False,
        'data_processed': False,
        'models_trained': False,
        'final_model_selected': False,
        'raw_df': None,
        'processed_df': None,
        'artifacts': {},
        'decision_threshold': 0.5
    }
    for key, default_value in session_state_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

@st.cache_data(show_spinner="Analisando o arquivo de dados...")
def load_and_profile_data():
    """
    Carrega os dados diretamente do arquivo padr√£o 'credit_customers.csv'
    e realiza um profiling completo, retornando o DataFrame e um dicion√°rio
    com as estat√≠sticas de qualidade dos dados.
    """
    try:
        df = pd.read_csv('credit_customers.csv')
    except FileNotFoundError:
        st.error("ERRO CR√çTICO: O arquivo padr√£o 'credit_customers.csv' n√£o foi encontrado. Certifique-se de que ele est√° no mesmo diret√≥rio do script `app.py`.")
        return None, None
    except Exception as e:
        st.error(f"Erro inesperado ao ler o arquivo: {e}")
        return None, None

    profile_summary = {
        'Vis√£o Geral': {
            'Clientes (Linhas)': df.shape[0],
            'Atributos (Colunas)': df.shape[1],
            'C√©lulas Faltando': df.isnull().sum().sum(),
            '% de Dados Faltando': f"{df.isnull().sum().sum() / df.size * 100:.2f}%",
            'Linhas Duplicadas': df.duplicated().sum()
        },
        'detalhes_variaveis': []
    }
    
    for col in df.columns:
        series = df[col]
        col_info = {
            'Atributo': col, 'Tipo': str(series.dtype),
            'Nulos (%)': f"{series.isnull().mean() * 100:.2f}%",
            'Valores √önicos': series.nunique()
        }
        if pd.api.types.is_numeric_dtype(series):
            q1, q3 = series.quantile(0.25), series.quantile(0.75)
            iqr = q3 - q1
            outliers = series[(series < (q1 - 1.5 * iqr)) | (series > (q3 + 1.5 * iqr))]
            col_info['Outliers (%)'] = f"{len(outliers) / len(series) * 100:.2f}%"
        profile_summary['detalhes_variaveis'].append(col_info)
    
    return df, profile_summary

@st.cache_data(show_spinner="Aplicando engenharia de features e transforma√ß√µes...")
def execute_feature_engineering(_df):
    """
    Executa um pipeline completo de limpeza e transforma√ß√£o de vari√°veis,
    adaptado para o dataset de risco de cr√©dito.
    """
    df = _df.copy()
    
    # Assegura que colunas categ√≥ricas sejam tratadas como string para evitar erros
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        df[col] = df[col].astype(str)
        
    # Codifica√ß√£o da vari√°vel-alvo para formato num√©rico
    # 'good' (bom risco) -> 0 | 'bad' (mau risco) -> 1
    le = LabelEncoder()
    df[ProjectConfig.TARGET_VARIABLE] = le.fit_transform(df[ProjectConfig.TARGET_VARIABLE])
    st.session_state.artifacts['label_encoder'] = le

    # Exemplo de cria√ß√£o de novas vari√°veis para capturar intera√ß√µes importantes
    # Esta etapa √© crucial para dar mais "mat√©ria-prima" aos modelos
    df['credit_to_duration_ratio'] = df['credit_amount'] / df['duration']
    df['credit_to_age_ratio'] = df['credit_amount'] / df['age']
    
    # Hip√≥tese: Pessoas mais jovens pedindo muito cr√©dito podem ser mais arriscadas
    df.loc[df['age'] < 25, 'young_high_credit'] = (df['credit_amount'] > df['credit_amount'].median()).astype(int)
    df['young_high_credit'].fillna(0, inplace=True)
    
    return df

def display_home_page():
    """
    Renderiza a p√°gina inicial de boas-vindas do dashboard.
    Apresenta a miss√£o do projeto e guia o usu√°rio sobre como navegar.
    """    
    st.title("Sistema de Apoio √† Decis√£o para An√°lise de Risco de Cr√©dito")
    st.subheader("Utilizando IA, XAI (SHAP) e Clusteriza√ß√£o para Decis√µes Gerenciais")
    st.markdown("---")
    
    st.markdown("""
    ### Bem-vindo(a), Analista de Risco!

    Esta plataforma interativa foi desenvolvida como a solu√ß√£o para a **Prova Final** da disciplina de Sistemas de Informa√ß√£o em Engenharia de Produ√ß√£o. O objetivo √© fornecer ao setor de risco de cr√©dito uma ferramenta completa para otimizar a concess√£o de cr√©dito, equilibrando a expans√£o da base de clientes com a sustentabilidade financeira da opera√ß√£o.
    """)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        with st.container(border=True):
            st.markdown("<h5 style='text-align: center;'>Prever o Risco</h5>", unsafe_allow_html=True)
            st.markdown("Utilizar modelos de Machine Learning para classificar novos clientes como bons (`good`) ou maus (`bad`) pagadores, com base em seus dados hist√≥ricos.")
    with col2:
        with st.container(border=True):
            st.markdown("<h5 style='text-align: center;'>Gerar Transpar√™ncia (XAI)</h5>", unsafe_allow_html=True)
            st.markdown("Empregar t√©cnicas de IA Explic√°vel com **SHAP** para entender os fatores que mais influenciam as decis√µes dos modelos, tornando-os audit√°veis e confi√°veis.")
    with col3:
        with st.container(border=True):
            st.markdown("<h5 style='text-align: center;'>Segmentar Clientes</h5>", unsafe_allow_html=True)
            st.markdown("Aplicar algoritmos n√£o supervisionados como **K-Means** e **DBSCAN** para descobrir perfis de clientes e identificar comportamentos at√≠picos (outliers).")

    st.markdown("---")
    st.info("Utilize o menu de navega√ß√£o na barra lateral esquerda para explorar as diferentes etapas desta an√°lise completa, desde a prepara√ß√£o dos dados at√© a tomada de decis√£o gerencial.", icon="üß≠")

def main():
    """
    Fun√ß√£o principal que controla a navega√ß√£o e a renderiza√ß√£o das p√°ginas
    do aplicativo Streamlit. √â o ponto central que orquestra toda a aplica√ß√£o.
    """
    initialize_session_state()
    px.defaults.template = ProjectConfig.get_plotly_template()

    st.sidebar.title("Painel de Controle üéõÔ∏è")
    st.sidebar.markdown("Navegue pelas etapas da an√°lise de risco de cr√©dito.")
    
    page_options = {
        "P√°gina Inicial": "üè†",
        "An√°lise e Prepara√ß√£o dos Dados": "üìä",
        "An√°lise Explorat√≥ria (EDA)": "üîç",
        "Modelagem Supervisionada": "‚öôÔ∏è",
        "Decis√£o Gerencial e N√£o Supervisionada": "üß†",
        "Documenta√ß√£o e Exporta√ß√£o": "üìÑ"
    }
    
    page_selection = st.sidebar.radio(
        "Menu de Navega√ß√£o:",
        options=page_options.keys(),
        format_func=lambda x: f"{page_options[x]} {x}" # Adiciona √≠cones ao r√°dio
    )
    
    st.sidebar.markdown("---")
    st.sidebar.markdown(
        """
        <div style='text-align: left; font-size: 0.9em;'>
            <strong>Prova Final</strong><br>
            <span>EPR0072 - Sistemas de Informa√ß√£o</span><br>
            <span>Prof. Jo√£o Gabriel de Moraes Souza</span>
        </div>
        """,
        unsafe_allow_html=True
    )

    # Roteamento das p√°ginas
    if page_selection == "P√°gina Inicial":
        display_home_page()
    elif page_selection == "An√°lise e Prepara√ß√£o dos Dados":
        display_dataset_page()
    elif page_selection == "An√°lise Explorat√≥ria (EDA)":
        display_eda_page()
    elif page_selection == "Modelagem Supervisionada":
        display_modeling_page()
    elif page_selection == "Decis√£o Gerencial e N√£o Supervisionada":
        display_advanced_analysis_page()
    elif page_selection == "Documenta√ß√£o e Exporta√ß√£o":
        display_export_and_docs_page(st.session_state.artifacts)

def display_dataset_page():
    """
    Renderiza a p√°gina de An√°lise e Prepara√ß√£o dos Dados, guiando o usu√°rio
    pelas etapas de auditoria, profiling e engenharia de features com
    explica√ß√µes detalhadas para cada passo.
    """
    st.header("An√°lise e Prepara√ß√£o dos Dados üìä")
    st.markdown("O primeiro passo em qualquer projeto de ci√™ncia de dados √© uma auditoria completa nos dados brutos para entender sua estrutura, qualidade e caracter√≠sticas. Esta etapa √© fundamental para o sucesso dos modelos.")

    if not st.session_state.data_loaded:
        raw_df, profile_results = load_and_profile_data()
        if raw_df is not None:
            st.session_state.raw_df = raw_df
            st.session_state.artifacts['profile_results'] = profile_results
            st.session_state.data_loaded = True
        else:
            st.stop()

    st.subheader("Auditoria e Profiling dos Dados Brutos")
    st.markdown("""
    A tabela detalhada abaixo √© o resultado da "entrevista" com nossos dados. Ela nos ajuda a responder perguntas cruciais que guiam o pr√©-processamento:

    - **Tipo:** A vari√°vel √© um n√∫mero, um texto ou uma categoria? Isso define como vamos trat√°-la.
    - **Nulos (%):** Existem dados faltando? A aus√™ncia de valores nulos neste dataset simplifica nosso trabalho.
    - **Outliers (%):** Existem valores extremos (calculados pelo M√©todo do IQR) que podem distorcer a an√°lise? Vemos que `credit_amount` e `age` possuem outliers que os modelos precisar√£o ser robustos para lidar.
    """)
    with st.expander("Visualizar Relat√≥rio Detalhado por Atributo", expanded=True):
        profile_df = pd.DataFrame(st.session_state.artifacts['profile_results']['detalhes_variaveis']).set_index('Atributo')
        st.dataframe(profile_df, use_container_width=True)

    st.markdown("---")
    
    st.subheader("Processamento e Engenharia de Features")
    st.markdown("Com os dados auditados, o pr√≥ximo passo √© transform√°-los para otimizar o desempenho dos modelos. Isso inclui a codifica√ß√£o de vari√°veis e a **Engenharia de Features**, que √© a arte de criar novos atributos a partir dos dados existentes para revelar padr√µes que n√£o eram √≥bvios.")
    
    if st.button("Executar Engenharia de Features", type="primary"):
        with st.spinner('Processando...'):
            processed_df = execute_feature_engineering(st.session_state.raw_df)
            st.session_state.processed_df = processed_df
            st.session_state.data_processed = True
            st.success("Pipeline de engenharia de features executado com sucesso!")

    if st.session_state.data_processed:
        st.subheader("Comparativo de Impacto: Antes vs. Depois da Transforma√ß√£o")
        st.markdown("""
        **Objetivo:** O prop√≥sito desta visualiza√ß√£o √© dar total transpar√™ncia ao pr√©-processamento, mostrando o valor agregado da nossa prepara√ß√£o de dados. Abaixo, comparamos uma amostra dos dados antes e depois da engenharia de features para que voc√™ possa ver as mudan√ßas concretas.

        **O que observar:**
        - **Na tabela "Antes"**: Note a coluna `class` com os valores em texto ('good', 'bad').
        - **Na tabela "Depois"**: Observe como a coluna `class` foi transformada em um alvo num√©rico (0 para 'good', 1 para 'bad'), que √© o formato que os modelos de IA entendem. Al√©m disso, veja as **novas colunas** √† direita (`credit_to_duration_ratio`, etc.), que foram criadas para fornecer mais informa√ß√µes e contexto para os algoritmos.
        """)
        
        # Seleciona colunas relevantes para a compara√ß√£o
        raw_cols_to_show = ['class', 'credit_amount', 'duration', 'age']
        processed_cols_to_show = ['class', 'credit_amount', 'duration', 'age', 'credit_to_duration_ratio', 'credit_to_age_ratio']
        
        # Garante que as colunas existem antes de tentar acess√°-las
        raw_sample = st.session_state.raw_df[raw_cols_to_show].head()
        processed_sample = st.session_state.processed_df[processed_cols_to_show].head()

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Tabela 1: Dados Brutos (Amostra)**")
            st.dataframe(raw_sample)
        with col2:
            st.markdown("**Tabela 2: Dados Processados (Amostra)**")
            st.dataframe(processed_sample)

        st.success("""
        **Conclus√£o da Etapa:** A transforma√ß√£o foi bem-sucedida. Os dados agora est√£o em um formato num√©rico, otimizado e enriquecido com novas features, prontos para a fase de An√°lise Explorat√≥ria e, subsequentemente, para o treinamento dos modelos preditivos.
        """)
        st.info("Com os dados devidamente preparados, agora podemos prosseguir para a **An√°lise Explorat√≥ria (EDA)** no menu lateral.", icon="‚úÖ")

@st.cache_data
def calculate_descriptive_stats(series):
    """
    Calcula um dicion√°rio de estat√≠sticas descritivas para uma vari√°vel num√©rica ou categ√≥rica.
    Esta fun√ß√£o √© armazenada em cache para otimizar a performance da aplica√ß√£o.
    """
    if pd.api.types.is_numeric_dtype(series):
        return {
            'M√©dia': series.mean(), 'Mediana': series.median(), 'Desvio Padr√£o': series.std(),
            'Vari√¢ncia': series.var(), 'M√≠nimo': series.min(), 'M√°ximo': series.max(),
            '25¬∫ Percentil': series.quantile(0.25), '75¬∫ Percentil': series.quantile(0.75),
            'Assimetria (Skew)': series.skew(), 'Curtose (Kurtosis)': series.kurt(),
            'Contagem': series.count(), 'Valores √önicos': series.nunique()
        }
    else:
        return {
            'Contagem': series.count(), 'Valores √önicos': series.nunique(),
            'Moda (Mais Frequente)': series.mode().iloc[0] if not series.mode().empty else 'N/A',
            'Frequ√™ncia da Moda': series.value_counts().iloc[0] if not series.value_counts().empty else 0
        }

def render_univariate_analysis_tab(df):
    """
    Renderiza a aba de An√°lise Univariada na p√°gina de EDA.
    Permite ao usu√°rio selecionar uma vari√°vel e visualizar sua distribui√ß√£o e estat√≠sticas.
    """
    st.subheader("An√°lise de Vari√°veis Individuais")
    st.markdown("Selecione um atributo para visualizar sua distribui√ß√£o e principais m√©tricas estat√≠sticas.")

    default_variable = 'credit_amount' if 'credit_amount' in df.columns else df.columns[0]
    variable_to_analyze = st.selectbox(
        "Selecione o atributo de interesse:",
        options=df.columns,
        index=list(df.columns).index(default_variable)
    )

    if variable_to_analyze:
        selected_series = df[variable_to_analyze]
        
        stats_col, plot_col = st.columns([1, 2])
        
        with stats_col:
            st.markdown(f"#### M√©tricas para **{variable_to_analyze}**")
            stats_dict = calculate_descriptive_stats(selected_series)
            stats_df = pd.DataFrame(stats_dict.items(), columns=['M√©trica', 'Valor'])
            st.dataframe(stats_df.style.format(precision=2), use_container_width=True)

        with plot_col:
            if pd.api.types.is_numeric_dtype(selected_series) and selected_series.nunique() > 2: # Exclui a vari√°vel alvo bin√°ria
                st.markdown(f"#### Distribui√ß√£o de **{variable_to_analyze}**")
                fig = make_subplots(rows=2, cols=1, row_heights=[0.7, 0.3], vertical_spacing=0.1,
                                    subplot_titles=("Histograma e Curva de Densidade", "Box Plot para Detec√ß√£o de Outliers"))
                
                fig.add_trace(go.Histogram(x=selected_series, name='Histograma', histnorm='probability density', marker_color=ProjectConfig.PRIMARY_COLOR), row=1, col=1)
                fig.add_trace(go.Box(x=selected_series, name='Box Plot', marker_color=ProjectConfig.ACCENT_COLOR), row=2, col=1)

                fig.update_layout(showlegend=False, height=500, margin=dict(t=40, b=10, l=10, r=10))
                st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
            
            else: 
                st.markdown(f"#### Frequ√™ncia de **{variable_to_analyze}**")
                counts = selected_series.value_counts()
                fig = px.bar(
                    counts, x=counts.index, y=counts.values,
                    title=f"Contagem de Categorias em {variable_to_analyze}",
                    labels={'x': variable_to_analyze, 'y': 'Contagem'},
                    text_auto=True, color=counts.index,
                    color_discrete_map={'good': ProjectConfig.GOOD_RISK_COLOR, 'bad': ProjectConfig.BAD_RISK_COLOR}
                )
                fig.update_layout(height=500, xaxis_title=variable_to_analyze, yaxis_title='Contagem', showlegend=False)
                st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})

def render_bivariate_analysis_tab(df):
    st.subheader("An√°lise da Rela√ß√£o entre Pares de Vari√°veis")
    st.markdown("Explore como diferentes caracter√≠sticas dos clientes se relacionam entre si e, principalmente, com a vari√°vel alvo `class` (0 para 'bom', 1 para 'mau').")
    
    numeric_options = df.select_dtypes(include=np.number).columns.drop('class', errors='ignore')
    
    col1, col2 = st.columns(2)
    with col1:
        var1 = st.selectbox("Selecione a primeira vari√°vel (Eixo X):", df.columns, index=df.columns.to_list().index('purpose'), key="bivar_1")
    with col2:
        var2 = st.selectbox("Selecione a segunda vari√°vel (Eixo Y ou Agrupamento):", df.columns, index=df.columns.to_list().index('credit_history'), key="bivar_2")

    if var1 and var2 and var1 != var2:
        is_var1_numeric = var1 in numeric_options
        is_var2_numeric = var2 in numeric_options

        if is_var1_numeric and is_var2_numeric:
            st.markdown(f"#### Correla√ß√£o Num√©rica: **{var1}** vs. **{var2}**")
            fig = px.scatter(
                df, x=var1, y=var2,
                color=df[ProjectConfig.TARGET_VARIABLE].map({0: 'Bom Risco', 1: 'Mau Risco'}),
                color_discrete_map={'Bom Risco': ProjectConfig.GOOD_RISK_COLOR, 'Mau Risco': ProjectConfig.BAD_RISK_COLOR},
                trendline="ols",
                title=f"Dispers√£o entre {var1} e {var2} por Risco de Cr√©dito"
            )
            fig.update_layout(height=500, legend_title_text='Status do Risco')
            st.plotly_chart(fig, use_container_width=True)

        elif not is_var1_numeric and not is_var2_numeric:
            st.markdown(f"#### Associa√ß√£o Categ√≥rica: **{var1}** vs. **{var2}**")
            st.markdown("Para analisar a rela√ß√£o entre duas vari√°veis categ√≥ricas, existem diferentes abordagens visuais. Abaixo apresentamos duas op√ß√µes:")

            st.markdown("##### Op√ß√£o 1: Tabela de Conting√™ncia e Mapa de Calor (Heatmap)")
            st.markdown("Esta abordagem √© excelente para ver a concentra√ß√£o de dados. C√©lulas mais escuras indicam uma combina√ß√£o mais frequente de categorias.")
            contingency_table = pd.crosstab(df[var1], df[var2])
            st.dataframe(contingency_table, use_container_width=True)
            fig_heatmap = px.imshow(
                contingency_table,
                text_auto=True,
                aspect="auto",
                title=f"Concentra√ß√£o de Clientes por {var1} e {var2}",
                color_continuous_scale='Blues'
            )
            fig_heatmap.update_layout(coloraxis_showscale=False)
            st.plotly_chart(fig_heatmap, use_container_width=True)
            
            st.markdown("---")

            st.markdown("##### Op√ß√£o 2: Gr√°fico de Barras Agrupado")
            st.markdown("Este gr√°fico ajuda a comparar as contagens de uma vari√°vel dentro de cada categoria da outra, de forma direta.")
            fig_grouped_bar = px.bar(
                df, x=var1, color=var2, barmode='group',
                title=f"Contagem Agrupada: {var1} vs. {var2}",
                text_auto=True
            )
            fig_grouped_bar.update_layout(height=500)
            st.plotly_chart(fig_grouped_bar, use_container_width=True)

        else:
            numeric_var = var1 if is_var1_numeric else var2
            categorical_var = var2 if is_var1_numeric else var1
            
            st.markdown(f"#### Compara√ß√£o de Distribui√ß√µes: **{numeric_var}** por **{categorical_var}**")
            st.markdown(f"O gr√°fico de violino abaixo √© excelente para comparar a distribui√ß√£o de uma vari√°vel num√©rica (`{numeric_var}`) entre as diferentes categorias de uma vari√°vel categ√≥rica (`{categorical_var}`).")
            fig_violin = px.violin(
                df, x=categorical_var, y=numeric_var,
                color=df[ProjectConfig.TARGET_VARIABLE].map({0: 'Bom Risco', 1: 'Mau Risco'}),
                box=True,
                points="all",
                title=f"Distribui√ß√£o de '{numeric_var}' por '{categorical_var}', segmentado por Risco",
                color_discrete_map={'Bom Risco': ProjectConfig.GOOD_RISK_COLOR, 'Mau Risco': ProjectConfig.BAD_RISK_COLOR}
            )
            fig_violin.update_layout(height=600, legend_title_text='Status do Risco')
            st.plotly_chart(fig_violin, use_container_width=True)

@st.cache_data(show_spinner="Calculando proje√ß√£o PCA para visualiza√ß√£o...")
def get_pca_projection(_df, target_col):
    """
    Executa a An√°lise de Componentes Principais (PCA) para reduzir
    a dimensionalidade dos dados num√©ricos para 2D, facilitando a visualiza√ß√£o.
    Retorna os componentes principais e a vari√¢ncia explicada.
    """
    numeric_cols = _df.select_dtypes(include=np.number).columns.drop(target_col, errors='ignore')
    
    pca_df = _df.copy()
    
    # Padroniza apenas as colunas num√©ricas antes do PCA
    scaler = StandardScaler()
    pca_df_scaled = scaler.fit_transform(pca_df[numeric_cols])
    
    pca = PCA(n_components=2, random_state=ProjectConfig.RANDOM_STATE_SEED)
    principal_components = pca.fit_transform(pca_df_scaled)
    
    pca_result_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
    pca_result_df[target_col] = pca_df[target_col].values
    
    explained_variance = pca.explained_variance_ratio_
    return pca_result_df, explained_variance

def render_multivariate_analysis_tab(df):
    """
    Renderiza a aba de An√°lise Multivariada, focando na visualiza√ß√£o
    de dados com PCA e gr√°ficos 3D interativos para uma explora√ß√£o mais profunda.
    """
    st.subheader("An√°lise de M√∫ltiplas Vari√°veis Simultaneamente")
    st.markdown("Explore intera√ß√µes complexas entre v√°rios atributos e como eles se relacionam com a vari√°vel alvo `class`.")
    
    numeric_cols = df.select_dtypes(include=np.number).columns.drop(ProjectConfig.TARGET_VARIABLE, errors='ignore').tolist()
    
    st.markdown("#### Visualiza√ß√£o do Espa√ßo de Features com PCA")
    st.markdown("""
    A An√°lise de Componentes Principais (PCA) reduz a complexidade dos dados, projetando-os em 2D. O gr√°fico abaixo nos ajuda a ver se existem agrupamentos naturais de clientes de 'bom risco' versus 'mau risco'. Uma boa separa√ß√£o visual aqui √© um bom press√°gio para os modelos de classifica√ß√£o.
    """)

    if st.button("Gerar Gr√°fico PCA", key="pca_button", type="primary"):
        pca_result_df, explained_variance = get_pca_projection(df, ProjectConfig.TARGET_VARIABLE)
        
        fig_pca = px.scatter(
            pca_result_df, x='PC1', y='PC2',
            color=pca_result_df[ProjectConfig.TARGET_VARIABLE].map({0: 'Bom Risco', 1: 'Mau Risco'}),
            color_discrete_map={'Bom Risco': ProjectConfig.GOOD_RISK_COLOR, 'Mau Risco': ProjectConfig.BAD_RISK_COLOR},
            title=f"Proje√ß√£o PCA 2D do Dataset (Vari√¢ncia Explicada: {sum(explained_variance):.2%})"
        )
        fig_pca.update_layout(height=600, legend_title_text='Status do Risco')
        st.plotly_chart(fig_pca, use_container_width=True)
    
    st.markdown("---")
    
    st.markdown("#### Scatter Plot 3D Interativo")
    st.markdown("Selecione tr√™s vari√°veis num√©ricas para criar um gr√°fico de dispers√£o 3D. A cor dos pontos representa o status do risco do cliente.")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        x_3d = st.selectbox("Eixo X:", numeric_cols, index=numeric_cols.index('age'), key="x_3d")
    with col2:
        y_3d = st.selectbox("Eixo Y:", numeric_cols, index=numeric_cols.index('credit_amount'), key="y_3d")
    with col3:
        z_3d = st.selectbox("Eixo Z:", numeric_cols, index=numeric_cols.index('duration'), key="z_3d")
    
    if x_3d and y_3d and z_3d:
        fig_3d = px.scatter_3d(
            df, x=x_3d, y=y_3d, z=z_3d,
            color=df[ProjectConfig.TARGET_VARIABLE].map({0: 'Bom Risco', 1: 'Mau Risco'}),
            color_discrete_map={'Bom Risco': ProjectConfig.GOOD_RISK_COLOR, 'Mau Risco': ProjectConfig.BAD_RISK_COLOR},
            title="Visualiza√ß√£o 3D Interativa de Features", height=700
        )
        fig_3d.update_traces(marker=dict(size=3, opacity=0.8))
        fig_3d.update_layout(legend_title_text='Status do Risco')
        st.plotly_chart(fig_3d, use_container_width=True)

def display_eda_page():
    """
    Renderiza a p√°gina principal de An√°lise Explorat√≥ria Interativa (EDA).
    Organiza as diferentes an√°lises (univariada, bivariada, multivariada) em abas
    e apresenta a an√°lise inicial de desbalanceamento de classes com explica√ß√µes detalhadas.
    """
    st.header("An√°lise Explorat√≥ria Interativa (EDA) üîç")
    st.markdown("""
    Nesta se√ß√£o, mergulhamos nos dados para descobrir padr√µes, correla√ß√µes e insights iniciais sobre o risco de cr√©dito.
    A An√°lise Explorat√≥ria √© um passo investigativo essencial antes de construirmos qualquer modelo preditivo.
    """)

    if not st.session_state.get('data_processed', False) or st.session_state.get('processed_df') is None:
        st.warning("‚ö†Ô∏è Os dados precisam ser processados na p√°gina 'An√°lise e Prepara√ß√£o dos Dados' para que a An√°lise Explorat√≥ria seja habilitada.")
        st.info("Por favor, retorne √† p√°gina anterior e clique no bot√£o 'Executar Engenharia de Features'.")
        return

    df = st.session_state.processed_df

    st.subheader("Diagn√≥stico da Vari√°vel-Alvo: `class`")
    st.markdown("""
    **Ponto de Partida: Entendendo o Desafio Central**

    Antes de analisar qualquer outra vari√°vel, precisamos entender a composi√ß√£o do nosso alvo: a coluna `class`. √â fundamental esclarecer que **n√£o estamos definindo quem √© bom ou mau pagador**. Essa defini√ß√£o √© uma regra de neg√≥cio j√° estabelecida: um cliente que atrasa o pagamento por mais de 90 dias √© classificado como `bad`.

    Nosso trabalho aqui √© um **diagn√≥stico**: Qual a propor√ß√£o desses clientes na nossa base de dados hist√≥rica? A resposta a essa pergunta define a principal estrat√©gia de modelagem.
    
    O c√°lculo √© simples:
    1.  Contamos o n√∫mero de clientes para cada categoria (`good` e `bad`).
    2.  Dividimos pelo total de clientes para encontrar a propor√ß√£o.
    """)
    
    col1, col2 = st.columns([1, 2])
    with col1:
        class_counts = df[ProjectConfig.TARGET_VARIABLE].value_counts()
        # Mapeia para os nomes originais para clareza
        class_counts.index = class_counts.index.map({0: 'Bom Risco (Good)', 1: 'Mau Risco (Bad)'})
        
        bom_risco_count = class_counts.get('Bom Risco (Good)', 0)
        mau_risco_count = class_counts.get('Mau Risco (Bad)', 0)
        total_count = bom_risco_count + mau_risco_count

        st.markdown(f"""
        **Resultados do Diagn√≥stico:**
        - **Bons Pagadores:** `{bom_risco_count}` clientes (`{bom_risco_count/total_count:.0%}`)
        - **Maus Pagadores:** `{mau_risco_count}` clientes (`{mau_risco_count/total_count:.0%}`)
        
        **Conclus√£o da An√°lise:** Os dados s√£o **desbalanceados**. Clientes de `mau risco` s√£o a minoria. Se n√£o tratarmos isso, um modelo de IA poderia ficar "pregui√ßoso" e aprender a simplesmente prever `bom risco` para todo mundo, atingindo uma alta acur√°cia, mas sendo completamente in√∫til para o neg√≥cio. Por isso, a t√©cnica **SMOTE** ser√° aplicada na fase de modelagem para balancear os dados de treino.
        """)

    with col2:
        fig_balance = px.pie(
            values=class_counts.values, names=class_counts.index, 
            title='Propor√ß√£o Hist√≥rica entre Bons e Maus Pagadores',
            color=class_counts.index,
            color_discrete_map={'Bom Risco (Good)': ProjectConfig.GOOD_RISK_COLOR, 'Mau Risco (Bad)': ProjectConfig.BAD_RISK_COLOR},
            hole=.3
        )
        st.plotly_chart(fig_balance, use_container_width=True)

    st.markdown("---")
    st.markdown("Agora que entendemos o desafio principal, vamos explorar as outras vari√°veis em mais detalhes nas abas abaixo.")

    tab_uni, tab_bi, tab_multi = st.tabs([
        "üìä An√°lise Univariada", 
        "üîó An√°lise Bivariada", 
        "üîÆ An√°lise Multivariada"
    ])

    with tab_uni:
        render_univariate_analysis_tab(df)
    with tab_bi:
        render_bivariate_analysis_tab(df)
    with tab_multi:
        render_multivariate_analysis_tab(df)

@st.cache_data(show_spinner="Dividindo dados, processando e aplicando SMOTE...")
def prepare_data_for_modeling(_df, target, test_size, random_state):
    """
    Executa o pipeline completo de prepara√ß√£o dos dados para a modelagem supervisionada.
    Isso inclui a separa√ß√£o dos dados, a cria√ß√£o de um pipeline de pr√©-processamento
    com ColumnTransformer e a aplica√ß√£o do SMOTE para balancear o conjunto de treino.
    Retorna um dicion√°rio contendo todos os artefatos de dados necess√°rios.
    """
    
    X = _df.drop(columns=[target])
    y = _df[target]
    
    # Divis√£o estratificada para manter a propor√ß√£o da vari√°vel alvo
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    numeric_features = X.select_dtypes(include=np.number).columns
    categorical_features = X.select_dtypes(exclude=np.number).columns
    
    # Pipeline de pr√©-processamento
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), categorical_features)
        ],
        remainder='passthrough',
        n_jobs=-1
    )
    
    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)
    
    try:
        ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
    except Exception:
        ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names(categorical_features)
        
    processed_feature_names = numeric_features.tolist() + list(ohe_feature_names)

    # Aplica√ß√£o do SMOTE para balanceamento da classe minorit√°ria
    smote = SMOTE(random_state=random_state, k_neighbors=5)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)
    
    # Armazena todos os artefatos em um dicion√°rio para uso futuro
    modeling_data = {
        'X_train_orig': X_train_processed, 'y_train_orig': y_train,
        'X_train_resampled': X_train_resampled, 'y_train_resampled': y_train_resampled,
        'X_test': X_test_processed, 'y_test': y_test,
        'preprocessor': preprocessor, 'processed_feature_names': processed_feature_names,
        'X_train_raw': X_train, 'X_test_raw': X_test
    }
    
    return modeling_data

def render_data_preparation_module(df):
    """
    Renderiza o m√≥dulo de UI para a prepara√ß√£o dos dados de modelagem.
    """
    with st.container(border=True):
        st.subheader("Etapa 1: Prepara√ß√£o e Balanceamento dos Dados")
        st.markdown("""
        **O Qu√™?** Realizamos tr√™s a√ß√µes cruciais:
        1.  **Divis√£o Estratificada:** Separamos os dados em Treino e Teste, mantendo a propor√ß√£o de bons/maus pagadores em ambos.
        2.  **Pr√©-processamento:** Padronizamos vari√°veis num√©ricas e codificamos as categ√≥ricas.
        3.  **Balanceamento com SMOTE:** Como temos poucos exemplos de 'maus pagadores', usamos SMOTE para criar exemplos sint√©ticos e realistas no conjunto de treino, ensinando o modelo a n√£o ignorar a classe minorit√°ria.
        """)
        
        if st.button("Executar Divis√£o e Balanceamento dos Dados", type="primary", key="prep_button"):
            modeling_data = prepare_data_for_modeling(df, ProjectConfig.TARGET_VARIABLE, ProjectConfig.TEST_SIZE_RATIO, ProjectConfig.RANDOM_STATE_SEED)
            st.session_state.artifacts['modeling_data'] = modeling_data
            st.session_state.app_stage = 'data_prepared'
            st.success("Dados preparados com sucesso!")
            st.rerun()

    if 'modeling_data' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            modeling_data = st.session_state.artifacts['modeling_data']
            st.subheader("Resultados da Prepara√ß√£o e Impacto Visual do SMOTE")
            st.markdown("Note como o conjunto de treino se tornou perfeitamente balanceado (50/50) ap√≥s o SMOTE. O gr√°fico PCA mostra visualmente esse impacto, transformando a nuvem de pontos minorit√°ria em um grupo denso e claro, ideal para o treinamento.")
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Clientes Treino (Original)", len(modeling_data['y_train_orig']))
            col2.metric("Clientes Teste", len(modeling_data['y_test']))
            col3.metric("Clientes Treino (P√≥s-SMOTE)", len(modeling_data['y_train_resampled']))

            with st.expander("Visualizar o Impacto do SMOTE (Proje√ß√£o PCA)", expanded=True):
                pca_vis = PCA(n_components=2, random_state=ProjectConfig.RANDOM_STATE_SEED)
                X_train_pca_before = pca_vis.fit_transform(modeling_data['X_train_orig'])
                X_train_pca_after = pca_vis.transform(modeling_data['X_train_resampled'])

                # CORRE√á√ÉO: Mapeia 0/1 para r√≥tulos de texto para a legenda funcionar
                labels_before = pd.Series(modeling_data['y_train_orig'].values).map({0: 'Bom Risco', 1: 'Mau Risco'})
                labels_after = pd.Series(modeling_data['y_train_resampled']).map({0: 'Bom Risco', 1: 'Mau Risco'})
                
                fig = make_subplots(rows=1, cols=2, subplot_titles=("Antes do SMOTE", "Depois do SMOTE"))
                
                # Gr√°fico 'Antes'
                fig.add_trace(go.Scatter(
                    x=X_train_pca_before[:, 0], y=X_train_pca_before[:, 1], mode='markers',
                    marker=dict(color=modeling_data['y_train_orig'].values, colorscale=[ProjectConfig.GOOD_RISK_COLOR, ProjectConfig.BAD_RISK_COLOR], showscale=False, opacity=0.7),
                    text=labels_before, customdata=labels_before, name='',
                    hovertemplate='<b>%{customdata}</b><br>PC1: %{x:.2f}<br>PC2: %{y:.2f}<extra></extra>'
                ), row=1, col=1)

                # Gr√°fico 'Depois'
                fig.add_trace(go.Scatter(
                    x=X_train_pca_after[:, 0], y=X_train_pca_after[:, 1], mode='markers',
                    marker=dict(color=modeling_data['y_train_resampled'], colorscale=[ProjectConfig.GOOD_RISK_COLOR, ProjectConfig.BAD_RISK_COLOR], showscale=False, opacity=0.7),
                    text=labels_after, customdata=labels_after, name='',
                    hovertemplate='<b>%{customdata}</b><br>PC1: %{x:.2f}<br>PC2: %{y:.2f}<extra></extra>'
                ), row=1, col=2)

                fig.update_layout(showlegend=False)
                st.plotly_chart(fig, use_container_width=True)

@st.cache_data(show_spinner="Executando Sele√ß√£o de Features com RFECV... Este processo pode ser intensivo.")
def run_rfe_cv_feature_selection(_modeling_data):
    """
    Executa a Elimina√ß√£o Recursiva de Features com Valida√ß√£o Cruzada (RFECV)
    para encontrar o subconjunto ideal de features que maximiza a performance
    preditiva, evitando ru√≠do e complexidade desnecess√°ria.

    A fun√ß√£o utiliza um estimador r√°pido e robusto (LGBMClassifier) para avaliar
    os subconjuntos de features, otimizando pela m√©trica ROC AUC em um esquema
    de valida√ß√£o cruzada estratificada para garantir a representatividade das classes.

    Retorna:
        dict: Um dicion√°rio contendo o objeto seletor treinado, o n√∫mero √≥timo de
              features, seus nomes, e os scores da valida√ß√£o cruzada para visualiza√ß√£o.
    """
    X_train = _modeling_data['X_train_resampled']
    y_train = _modeling_data['y_train_resampled']
    feature_names = _modeling_data['processed_feature_names']
    
    # Define um estimador leve para o processo de sele√ß√£o
    estimator_for_rfe = LGBMClassifier(
        random_state=ProjectConfig.RANDOM_STATE_SEED, 
        verbose=-1
    )
    
    # Configura a estrat√©gia de valida√ß√£o cruzada
    cv_strategy = StratifiedKFold(
        n_splits=ProjectConfig.N_SPLITS_KFOLD, 
        shuffle=True, 
        random_state=ProjectConfig.RANDOM_STATE_SEED
    )
    
    # Instancia o seletor RFECV
    rfe_selector = RFECV(
        estimator=estimator_for_rfe,
        step=1,
        cv=cv_strategy,
        scoring=ProjectConfig.RFE_CV_SCORING,
        min_features_to_select=10,  # Garante um m√≠nimo de features para o modelo
        n_jobs=-1
    )
    
    rfe_selector.fit(X_train, y_train)
    
    selected_feature_names = [
        feature for feature, support in zip(feature_names, rfe_selector.support_) if support
    ]

    # Em vers√µes mais recentes do scikit-learn, o atributo √© 'cv_results_'
    if hasattr(rfe_selector, 'cv_results_'):
        cv_results = rfe_selector.cv_results_['mean_test_score']
    else:
        # Fallback para vers√µes mais antigas
        cv_results = getattr(rfe_selector, 'grid_scores_', None)


    selection_artifacts = {
        'selector_object': rfe_selector,
        'optimal_n_features': rfe_selector.n_features_,
        'selected_feature_names': selected_feature_names,
        'cv_results_scores': cv_results,
    }
    
    return selection_artifacts

# NOVO C√ìDIGO - Substitua sua fun√ß√£o render_feature_selection_module por esta.
def render_feature_selection_module(modeling_data):
    """
    Renderiza o m√≥dulo de Sele√ß√£o de Features.
    Usa o "Interruptor M√°gico" para decidir se executa a pesquisa demorada
    ou se apenas mostra o resultado instantaneamente.
    """
    with st.container(border=True):
        st.subheader("Etapa 2: Foco no que Importa - Sele√ß√£o de Features")

        if MODO_PESQUISA:
            # --- MODO LIGADO: S√ì PARA O DESENVOLVEDOR ---
            st.warning("‚ö†Ô∏è MODO PESQUISA ATIVADO. A an√°lise lenta do RFECV ser√° executada.", icon="üî¨")
            st.info("Aguarde o processo terminar.")

            # Executa a fun√ß√£o lenta original
            selection_artifacts = run_rfe_cv_feature_selection(modeling_data)
            selected_features = selection_artifacts['selected_feature_names']
            
            st.success("Pesquisa Conclu√≠da! Copie a lista abaixo:")
            # Exibe a lista de forma f√°cil de copiar
            st.code(f"FEATURES_PRE_SELECIONADAS = {selected_features}")
            st.stop() # Para a execu√ß√£o do app aqui, pois o objetivo foi s√≥ pegar a lista.

        else:
            # --- MODO DESLIGADO: PARA O USU√ÅRIO FINAL ---
            st.markdown("""
            Para garantir a m√°xima performance, a sele√ß√£o das melhores features foi realizada com o robusto m√©todo **RFECV**. Este processo computacionalmente intensivo foi executado previamente, e seus resultados est√£o carregados abaixo instantaneamente.
            """)
            
            if not FEATURES_PRE_SELECIONADAS:
                st.error("ERRO: A lista 'FEATURES_PRE_SELECIONADAS' est√° vazia. Voc√™ precisa executar o MODO PESQUISA primeiro.")
                st.stop()

            st.metric(label="N√∫mero ideal de features (pr√©-calculado)", value=len(FEATURES_PRE_SELECIONADAS))

            with st.expander("Visualizar a Lista de Features Selecionadas"):
                st.dataframe(pd.DataFrame(FEATURES_PRE_SELECIONADAS, columns=["Feature Selecionada"]), use_container_width=True)

            # Prepara os artefatos para o resto do app funcionar
            if 'selection_artifacts' not in st.session_state.get('artifacts', {}):
                # Classe auxiliar para simular o seletor
                class PrecomputedSelector:
                    def __init__(self, feature_list):
                        self.feature_list = feature_list
                    def transform(self, X):
                        df = pd.DataFrame(X, columns=modeling_data['processed_feature_names'])
                        return df[self.feature_list].values
                
                st.session_state.artifacts['selection_artifacts'] = {
                    'selector_object': PrecomputedSelector(FEATURES_PRE_SELECIONADAS),
                    'optimal_n_features': len(FEATURES_PRE_SELECIONADAS),
                    'selected_feature_names': FEATURES_PRE_SELECIONADAS
                }
            
            st.success("Features carregadas! Podemos prosseguir para a competi√ß√£o de modelos.", icon="‚úÖ")

@st.cache_data(show_spinner="Treinando e avaliando todos os 9 modelos... Este processo pode levar alguns minutos.")
def train_baseline_models(_modeling_data, _selection_artifacts):
    """
    Treina uma lista completa de modelos de classifica√ß√£o, incluindo todos os
    solicitados na Prova Final. Avalia a performance de cada um no conjunto de
    teste e retorna um dicion√°rio com todos os modelos, m√©tricas e artefatos.
    """
    X_train = _modeling_data['X_train_resampled']
    y_train = _modeling_data['y_train_resampled']
    X_test = _modeling_data['X_test']
    y_test = _modeling_data['y_test']

    selector = _selection_artifacts['selector_object']
    X_train_final = selector.transform(X_train)
    X_test_final = selector.transform(X_test)
    
    models_to_test = {
        "Regress√£o Log√≠stica": LogisticRegression(random_state=ProjectConfig.RANDOM_STATE_SEED, max_iter=1000, n_jobs=-1),
        "KNN": KNeighborsClassifier(n_jobs=-1),
        "SVM": SVC(probability=True, random_state=ProjectConfig.RANDOM_STATE_SEED),
        "√Årvore de Decis√£o": DecisionTreeClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "Random Forest": RandomForestClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, n_jobs=-1),
        "AdaBoost": AdaBoostClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "Gradient Boosting": GradientBoostingClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "XGBoost": XGBClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, use_label_encoder=False, eval_metric='logloss'),
        "LightGBM": LGBMClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, verbose=-1),
        "Rede Neural (MLP)": MLPClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, max_iter=500, early_stopping=True, hidden_layer_sizes=(50, 25))
    }

    baseline_results = {}
    progress_bar = st.progress(0, text="Iniciando treinamento dos modelos...")

    for i, (name, model) in enumerate(models_to_test.items()):
        progress_bar.progress((i + 1) / len(models_to_test), text=f"Treinando modelo: {name}...")
        
        # Usamos um pipeline para modelos que n√£o s√£o de √°rvore para garantir consist√™ncia
        if not hasattr(model, 'feature_importances_') and not name == "SVM":
             pipeline = ImbPipeline([('model', model)])
        else:
             pipeline = model

        pipeline.fit(X_train_final, y_train)
        y_pred = pipeline.predict(X_test_final)
        y_proba = pipeline.predict_proba(X_test_final)[:, 1]
        
        baseline_results[name] = {
            'model_object': pipeline,
            'metrics': {
                'AUC': roc_auc_score(y_test, y_proba),
                'Acur√°cia': accuracy_score(y_test, y_pred),
                'Recall': recall_score(y_test, y_pred),
                'Precis√£o': precision_score(y_test, y_pred),
                'F1-Score': f1_score(y_test, y_pred)
            },
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'full_report': classification_report(y_test, y_pred, output_dict=True, target_names=['Bom Risco', 'Mau Risco']),
            'roc_curve_data': roc_curve(y_test, y_proba)
        }
    progress_bar.empty()
    return baseline_results

def render_baseline_modeling_module(modeling_data, selection_artifacts):
    """
    Renderiza o m√≥dulo de UI para o treinamento dos modelos de baseline.
    Apresenta um leaderboard interativo para comparar a performance dos algoritmos.
    """
    with st.container(border=True):
        st.subheader("Etapa 3: A Competi√ß√£o dos Modelos Supervisionados")
        st.markdown("""
        **O Qu√™?** Agora come√ßa a competi√ß√£o! Treinamos todos os 9 modelos de classifica√ß√£o solicitados no desafio, usando os dados preparados e as features selecionadas na etapa anterior. Cada modelo √© avaliado com um conjunto rigoroso de m√©tricas de performance no conjunto de teste, que ele nunca viu antes.

        **Por qu√™?** Esta competi√ß√£o nos permite comparar objetivamente a efic√°cia de diferentes abordagens algor√≠tmicas para o nosso problema de risco de cr√©dito. O **Leaderboard de Performance** abaixo resume os resultados, permitindo-nos identificar os modelos mais promissores para uma an√°lise mais profunda.
        """)
        
        if st.button("Executar Competi√ß√£o de Modelos", key="train_button", type="primary"):
            baseline_artifacts = train_baseline_models(modeling_data, selection_artifacts)
            if baseline_artifacts:
                st.session_state.artifacts['baseline_artifacts'] = baseline_artifacts
                st.session_state.app_stage = 'baselines_trained'
                st.success("Competi√ß√£o de modelos baseline conclu√≠da com sucesso!")
                st.rerun()

    if 'baseline_artifacts' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            artifacts = st.session_state.artifacts['baseline_artifacts']
            st.subheader("An√°lise P√≥s-Treinamento: O Leaderboard de Performance")
            st.markdown("""
            **Como interpretar:** Ordene a tabela clicando nos cabe√ßalhos das colunas.
            - **AUC:** A principal m√©trica de performance geral (pr√≥ximo de 1.0 √© melhor).
            - **Recall:** Crucial para o neg√≥cio! Mostra a porcentagem de **maus pagadores** que o modelo conseguiu identificar corretamente. Um Recall alto evita que clientes de risco passem despercebidos.
            - **Precis√£o:** Dos clientes que o modelo previu como `mau` risco, quantos realmente eram.
            - **F1-Score:** Uma m√©dia harm√¥nica entre Precis√£o e Recall.
            """)
            
            leaderboard_data = [{'Modelo': name, **res['metrics']} for name, res in artifacts.items()]
            leaderboard_df = pd.DataFrame(leaderboard_data).set_index('Modelo')
            
            sort_by = st.selectbox("Ordenar leaderboard pela m√©trica:", leaderboard_df.columns, index=0)
            sorted_df = leaderboard_df.sort_values(by=sort_by, ascending=False)
            st.dataframe(
                sorted_df.style.background_gradient(cmap='viridis', subset=[sort_by], low=0.6)
                               .format("{:.4f}")
                               .highlight_max(subset=[sort_by], color='#94d2bd'),
                use_container_width=True
            )
            st.info("Com o leaderboard, podemos agora fazer uma an√°lise aprofundada de cada competidor.", icon="üî¨")

def render_roc_tab(model_data, model_name):
    """
    Renderiza o conte√∫do da aba 'Curva ROC' no m√≥dulo de an√°lise aprofundada.
    """
    metrics = model_data['metrics']
    fpr, tpr, _ = model_data['roc_curve_data']

    fig_roc = go.Figure()
    fig_roc.add_trace(go.Scatter(
        x=fpr, y=tpr, 
        mode='lines', 
        name=f'Curva ROC (AUC = {metrics["AUC"]:.4f})', 
        line=dict(color=ProjectConfig.PRIMARY_COLOR, width=4)
    ))
    fig_roc.add_trace(go.Scatter(
        x=[0, 1], y=[0, 1], 
        mode='lines', 
        name='Performance Aleat√≥ria (AUC = 0.5)',
        line=dict(color=ProjectConfig.ACCENT_COLOR, dash='dash')
    ))
    
    fig_roc.update_layout(
        title=f"Curva ROC para o Modelo: {model_name}",
        xaxis_title='Taxa de Falsos Positivos (1 - Especificidade)',
        yaxis_title='Taxa de Verdadeiros Positivos (Recall / Sensibilidade)',
        legend=dict(x=0.55, y=0.1, bgcolor='rgba(255,255,255,0.6)'),
        height=500
    )
    st.plotly_chart(fig_roc, use_container_width=True, key=f"deep_dive_roc_{model_name}")

def render_report_tab(model_data):
    """
    Renderiza o conte√∫do da aba 'Relat√≥rio Completo'.
    """
    st.markdown("O relat√≥rio abaixo detalha as m√©tricas para cada classe.")
    report_df = pd.DataFrame(model_data['full_report']).transpose()
    st.dataframe(report_df.style.format("{:.3f}"), use_container_width=True)

def render_importance_tab(model_data, model_name):
    """
    Renderiza o conte√∫do da aba 'Import√¢ncia de Features'.
    """
    if hasattr(model_data['model_object'], 'steps'):
        model_object = model_data['model_object'].steps[-1][1]
    else:
        model_object = model_data['model_object']
    
    importances = None
    if hasattr(model_object, 'feature_importances_'):
        importances = model_object.feature_importances_
    elif hasattr(model_object, 'coef_'):
        importances = np.abs(model_object.coef_[0])

    if importances is not None:
        feature_names = st.session_state['artifacts']['selection_artifacts']['selected_feature_names']
        if len(feature_names) == len(importances):
            importance_df = pd.DataFrame({'Feature': feature_names, 'Import√¢ncia': importances}).sort_values(by='Import√¢ncia', ascending=False)
            fig_imp = px.bar(
                importance_df.head(20).sort_values(by='Import√¢ncia', ascending=True), 
                x='Import√¢ncia', y='Feature', orientation='h', 
                title=f"Top 20 Features Mais Importantes para o Modelo: {model_name}"
            )
            st.plotly_chart(fig_imp, use_container_width=True, key=f"deep_dive_importance_{model_name}")
    else:
        st.info(f"O modelo '{model_name}' n√£o possui um atributo de import√¢ncia de features direto. A an√°lise com SHAP na pr√≥xima etapa √© a mais indicada.", icon="‚ÑπÔ∏è")

def render_model_deep_dive_module(baseline_artifacts):
    """
    Renderiza o m√≥dulo de UI para an√°lise detalhada de cada modelo treinado.
    Utiliza abas para organizar as diferentes visualiza√ß√µes e an√°lises,
    come√ßando pela crucial Matriz de Confus√£o.
    """
    with st.container(border=True):
        st.subheader("Etapa 4: An√°lise Aprofundada dos Competidores")
        st.markdown("""
        **O Qu√™?** Escolha um modelo do leaderboard para uma inspe√ß√£o detalhada. Aqui, vamos al√©m das m√©tricas gerais e investigamos *como* cada modelo acerta e erra.
        
        **Por qu√™?** Entender os pontos fortes e fracos de cada algoritmo √© essencial para a **tomada de decis√£o gerencial**. A **Matriz de Confus√£o** √© nossa principal ferramenta aqui. Ela nos mostra os quatro cen√°rios poss√≠veis:
        - **Verdadeiros Negativos (VN):** Modelo previu `Bom Risco`, e acertou.
        - **Verdadeiros Positivos (VP):** Modelo previu `Mau Risco`, e acertou.
        - **Falsos Positivos (FP):** Modelo previu `Mau Risco`, mas errou (custo de oportunidade, cliente bom negado).
        - **Falsos Negativos (FN):** Modelo previu `Bom Risco`, mas errou (preju√≠zo, cliente mau aprovado). **Este √© o erro mais caro para o neg√≥cio!**
        """)
        
        # Ordena os modelos por AUC para sugerir o melhor primeiro
        sorted_models = sorted(baseline_artifacts.keys(), key=lambda k: baseline_artifacts[k]['metrics']['AUC'], reverse=True)

        model_to_inspect = st.selectbox(
            "Selecione um modelo do leaderboard para uma an√°lise detalhada:",
            options=sorted_models
        )
        
        if model_to_inspect:
            model_explanations = {
            "Regress√£o Log√≠stica": {
                "desc": "Um modelo estat√≠stico fundamental para classifica√ß√£o bin√°ria. Ele estima a probabilidade de um evento ocorrer (neste caso, `mau risco`) com base nos valores das vari√°veis de entrada, aplicando uma fun√ß√£o log√≠stica.",
                "decision": "Sua principal vantagem √© a **interpretabilidade**. Os coeficientes do modelo nos dizem exatamente o quanto cada vari√°vel aumenta ou diminui a chance de inadimpl√™ncia, permitindo criar pol√≠ticas de cr√©dito extremamente claras e baseadas em evid√™ncias estat√≠sticas."
            },
            "KNN": {
                "desc": "K-Nearest Neighbors (Vizinhos Mais Pr√≥ximos) √© um algoritmo baseado em inst√¢ncia. Ele classifica um novo cliente com base na classe da maioria dos 'K' vizinhos mais pr√≥ximos a ele no espa√ßo de features. √â intuitivo e n√£o assume nenhuma premissa sobre a distribui√ß√£o dos dados.",
                "decision": "√â √∫til para encontrar padr√µes locais e n√£o lineares que outros modelos podem perder. Na tomada de decis√£o, ajuda a identificar 'bols√µes' de risco: clientes que, embora pare√ßam bons isoladamente, est√£o cercados por um 'bairro' de maus pagadores."
            },
            "SVM": {
                "desc": "Support Vector Machine (M√°quina de Vetores de Suporte) busca encontrar o 'hiperplano' (uma linha ou plano) que melhor separa as duas classes (bons e maus pagadores) com a maior margem poss√≠vel. Usando 'kernels', ele consegue encontrar fronteiras de decis√£o complexas e n√£o lineares.",
                "decision": "A for√ßa do SVM est√° em sua capacidade de lidar com dados de alta dimensionalidade e encontrar rela√ß√µes complexas. Para a decis√£o, ele √© excelente em identificar os casos mais dif√≠ceis e amb√≠guos que ficam perto da fronteira entre ser um bom ou mau pagador."
            },
            "√Årvore de Decis√£o": {
                "desc": "Cria um modelo semelhante a um fluxograma de decis√µes. Cada 'n√≥' da √°rvore representa um teste em uma vari√°vel (ex: 'dura√ß√£o > 12 meses?'), e cada 'folha' representa uma classifica√ß√£o (bom ou mau risco).",
                "decision": "Sua maior vantagem √© a **transpar√™ncia**. Uma √°rvore de decis√£o √© facilmente visualiz√°vel e compreendida por qualquer pessoa do time de neg√≥cios, tornando a regra de decis√£o expl√≠cita. √â a base para modelos mais complexos como o Random Forest."
            },
            "Random Forest": {
                "desc": "√â um modelo de 'ensemble' (conjunto) que constr√≥i m√∫ltiplas √°rvores de decis√£o durante o treinamento e decide a classifica√ß√£o final com base na 'vota√ß√£o' da maioria das √°rvores. Isso reduz o superajuste (overfitting) e melhora a generaliza√ß√£o.",
                "decision": "Para a tomada de decis√£o, o Random Forest oferece um excelente equil√≠brio entre alta performance preditiva e boa interpretabilidade (podemos ver a import√¢ncia m√©dia das features). Ele √© robusto e geralmente fornece previs√µes muito est√°veis."
            },
            "AdaBoost": {
                "desc": "Adaptive Boosting √© um algoritmo de 'boosting'. Ele treina uma sequ√™ncia de modelos fracos (geralmente pequenas √°rvores), onde cada novo modelo d√° mais aten√ß√£o aos erros de classifica√ß√£o do modelo anterior. O resultado final √© uma soma ponderada de todos os modelos.",
                "decision": "Sua natureza adaptativa o torna eficaz em casos dif√≠ceis. Para a decis√£o, ele ajuda a focar nos perfis de clientes que s√£o consistentemente classificados de forma errada, permitindo a cria√ß√£o de pol√≠ticas espec√≠ficas para esses nichos de maior incerteza."
            },
            "Gradient Boosting": {
                "desc": "Assim como o AdaBoost, treina modelos em sequ√™ncia. No entanto, em vez de ajustar os pesos dos erros, cada novo modelo tenta corrigir o 'erro residual' (a diferen√ßa entre a previs√£o e o valor real) do modelo anterior. √â um dos algoritmos mais perform√°ticos.",
                "decision": "Oferece alt√≠ssima precis√£o. Para a decis√£o gerencial, um modelo de Gradient Boosting bem ajustado pode ser a ferramenta definitiva para criar um score de cr√©dito extremamente acurado, minimizando perdas por aprovar clientes de alto risco."
            },
            "XGBoost": {
                "desc": "eXtreme Gradient Boosting √© uma implementa√ß√£o otimizada e de alta performance do Gradient Boosting. Inclui regulariza√ß√£o para evitar overfitting, tratamento de dados faltantes e processamento paralelo, tornando-o mais r√°pido e robusto.",
                "decision": "√â o padr√£o ouro em muitas competi√ß√µes de dados por um motivo: performance. Na tomada de decis√£o, um modelo XGBoost pode ser a base de um sistema de aprova√ß√£o de cr√©dito automatizado de alta performance, capaz de processar milhares de solicita√ß√µes com grande precis√£o."
            },
            "LightGBM": {
                "desc": "Light Gradient Boosting Machine √© outra implementa√ß√£o de boosting, focada em velocidade e efici√™ncia de mem√≥ria. Ele cresce as √°rvores 'folha por folha' em vez de 'n√≠vel por n√≠vel', o que o torna extremamente r√°pido em grandes datasets.",
                "decision": "Sua velocidade o torna ideal para ambientes de produ√ß√£o que exigem decis√µes em tempo real ou retreinamento frequente dos modelos. Para a gest√£o, significa ter um sistema de risco que pode ser atualizado diariamente com novos dados sem comprometer a performance."
            },
            "Rede Neural (MLP)": {
                "desc": "Multi-layer Perceptron √© um modelo inspirado no c√©rebro humano, com camadas de 'neur√¥nios' interconectados. Ele √© capaz de aprender padr√µes extremamente complexos e n√£o lineares nos dados.",
                "decision": "Sua for√ßa est√° na capacidade de capturar intera√ß√µes sutis entre as vari√°veis que outros modelos podem n√£o ver. Para a decis√£o, pode revelar perfis de risco n√£o intuitivos, justificando pol√≠ticas de cr√©dito inovadoras e altamente segmentadas."
            }
        }
        
        explanation = model_explanations.get(model_to_inspect, {})
        if explanation:
            with st.expander(f"Entendendo o Modelo: {model_to_inspect}", expanded=True):
                st.markdown(f"**Como Funciona:** {explanation['desc']}")
                st.markdown(f"**Relev√¢ncia para a Tomada de Decis√£o:** {explanation['decision']}")

            model_data = baseline_artifacts[model_to_inspect]
            metrics = model_data['metrics']
            
            st.markdown(f"##### M√©tricas de Performance para o Modelo **{model_to_inspect}**")
        
        metric_explanations = {
            "AUC": "Mede a capacidade geral do modelo de distinguir entre bons e maus pagadores. Quanto mais perto de 1.0, melhor o modelo.",
            "Acur√°cia": "Percentual geral de acertos. Pode ser enganosa em dados desbalanceados, por isso olhamos outras m√©tricas.",
            "Recall": "A m√©trica mais importante para o risco! Dos clientes que realmente eram 'maus', quantos o modelo conseguiu capturar? Um recall alto evita preju√≠zos.",
            "Precis√£o": "Dos clientes que o modelo classificou como 'maus', quantos ele acertou? Uma precis√£o alta evita negar cr√©dito a bons clientes.",
            "F1-Score": "Uma m√©dia harm√¥nica entre Precis√£o e Recall. √ötil para um balan√ßo geral da performance na classe positiva ('mau risco')."
        }

        metric_cols = st.columns(len(metrics))
        for i, (metric_name, metric_value) in enumerate(metrics.items()):
            help_text = metric_explanations.get(metric_name, "")
            metric_cols[i].metric(metric_name, f"{metric_value:.4f}", help=help_text)

            tab_cm, tab_roc, tab_report, tab_importance = st.tabs(["Matriz de Confus√£o", "Curva ROC", "Relat√≥rio Detalhado", "Import√¢ncia de Features"])

            with tab_cm:
                cm = model_data['confusion_matrix']
                fig_cm = px.imshow(
                    cm, text_auto=True, aspect="auto",
                    labels=dict(x="Valores Previstos pelo Modelo", y="Valores Reais da Base de Teste"),
                    x=['Bom Risco', 'Mau Risco'], y=['Bom Risco', 'Mau Risco'],
                    title=f"Matriz de Confus√£o para o Modelo: {model_to_inspect}",
                    color_continuous_scale='Blues'
                )
                fig_cm.update_layout(coloraxis_showscale=False)
                st.plotly_chart(fig_cm, use_container_width=True, key=f"plotly_cm_{model_to_inspect}")
                st.warning(f"O modelo falhou em identificar **{cm[1, 0]}** clientes de alto risco (Falsos Negativos), que representam o maior preju√≠zo potencial. Por outro lado, classificou erroneamente **{cm[0, 1]}** bons clientes como de alto risco (Falsos Positivos).")

            with tab_roc:
                render_roc_tab(model_data, model_to_inspect)
            
            with tab_report:
                render_report_tab(model_data)

            with tab_importance:
                render_importance_tab(model_data, model_to_inspect)

def render_model_deep_dive_module(baseline_artifacts):
    with st.container(border=True):
        st.subheader("Etapa 4: An√°lise Aprofundada dos Competidores")
        st.markdown("""
        **O Qu√™?** Escolha um modelo do leaderboard para uma inspe√ß√£o detalhada. Aqui, vamos al√©m das m√©tricas gerais e investigamos *como* cada modelo acerta e erra.
        
        **Por qu√™?** Entender os pontos fortes e fracos de cada algoritmo √© essencial para a **tomada de decis√£o gerencial**. A **Matriz de Confus√£o** √© nossa principal ferramenta aqui.
        """)
        
        sorted_models = sorted(baseline_artifacts.keys(), key=lambda k: baseline_artifacts[k]['metrics']['AUC'], reverse=True)
        model_to_inspect = st.selectbox(
            "Selecione um modelo do leaderboard para uma an√°lise detalhada:",
            options=sorted_models
        )
        
        if model_to_inspect:
            model_explanations = {
                "Regress√£o Log√≠stica": {
                    "desc": "Um modelo estat√≠stico fundamental para classifica√ß√£o bin√°ria. Ele estima a probabilidade de um evento ocorrer (neste caso, `mau risco`) com base nos valores das vari√°veis de entrada, aplicando uma fun√ß√£o log√≠stica.",
                    "decision": "Sua principal vantagem √© a **interpretabilidade**. Os coeficientes do modelo nos dizem exatamente o quanto cada vari√°vel aumenta ou diminui a chance de inadimpl√™ncia, permitindo criar pol√≠ticas de cr√©dito extremamente claras e baseadas em evid√™ncias estat√≠sticas."
                },
                "KNN": {
                    "desc": "K-Nearest Neighbors (Vizinhos Mais Pr√≥ximos) √© um algoritmo baseado em inst√¢ncia. Ele classifica um novo cliente com base na classe da maioria dos 'K' vizinhos mais pr√≥ximos a ele no espa√ßo de features. √â intuitivo e n√£o assume nenhuma premissa sobre a distribui√ß√£o dos dados.",
                    "decision": "√â √∫til para encontrar padr√µes locais e n√£o lineares que outros modelos podem perder. Na tomada de decis√£o, ajuda a identificar 'bols√µes' de risco: clientes que, embora pare√ßam bons isoladamente, est√£o cercados por um 'bairro' de maus pagadores."
                },
                "SVM": {
                    "desc": "Support Vector Machine (M√°quina de Vetores de Suporte) busca encontrar o 'hiperplano' (uma linha ou plano) que melhor separa as duas classes (bons e maus pagadores) com a maior margem poss√≠vel. Usando 'kernels', ele consegue encontrar fronteiras de decis√£o complexas e n√£o lineares.",
                    "decision": "A for√ßa do SVM est√° em sua capacidade de lidar com dados de alta dimensionalidade e encontrar rela√ß√µes complexas. Para a decis√£o, ele √© excelente em identificar os casos mais dif√≠ceis e amb√≠guos que ficam perto da fronteira entre ser um bom ou mau pagador."
                },
                "√Årvore de Decis√£o": {
                    "desc": "Cria um modelo semelhante a um fluxograma de decis√µes. Cada 'n√≥' da √°rvore representa um teste em uma vari√°vel (ex: 'dura√ß√£o > 12 meses?'), e cada 'folha' representa uma classifica√ß√£o (bom ou mau risco).",
                    "decision": "Sua maior vantagem √© a **transpar√™ncia**. Uma √°rvore de decis√£o √© facilmente visualiz√°vel e compreendida por qualquer pessoa do time de neg√≥cios, tornando a regra de decis√£o expl√≠cita. √â a base para modelos mais complexos como o Random Forest."
                },
                "Random Forest": {
                    "desc": "√â um modelo de 'ensemble' (conjunto) que constr√≥i m√∫ltiplas √°rvores de decis√£o durante o treinamento e decide a classifica√ß√£o final com base na 'vota√ß√£o' da maioria das √°rvores. Isso reduz o superajuste (overfitting) e melhora a generaliza√ß√£o.",
                    "decision": "Para a tomada de decis√£o, o Random Forest oferece um excelente equil√≠brio entre alta performance preditiva e boa interpretabilidade (podemos ver a import√¢ncia m√©dia das features). Ele √© robusto e geralmente fornece previs√µes muito est√°veis."
                },
                "AdaBoost": {
                    "desc": "Adaptive Boosting √© um algoritmo de 'boosting'. Ele treina uma sequ√™ncia de modelos fracos (geralmente pequenas √°rvores), onde cada novo modelo d√° mais aten√ß√£o aos erros de classifica√ß√£o do modelo anterior. O resultado final √© uma soma ponderada de todos os modelos.",
                    "decision": "Sua natureza adaptativa o torna eficaz em casos dif√≠ceis. Para a decis√£o, ele ajuda a focar nos perfis de clientes que s√£o consistentemente classificados de forma errada, permitindo a cria√ß√£o de pol√≠ticas espec√≠ficas para esses nichos de maior incerteza."
                },
                "Gradient Boosting": {
                    "desc": "Assim como o AdaBoost, treina modelos em sequ√™ncia. No entanto, em vez de ajustar os pesos dos erros, cada novo modelo tenta corrigir o 'erro residual' (a diferen√ßa entre a previs√£o e o valor real) do modelo anterior. √â um dos algoritmos mais perform√°ticos.",
                    "decision": "Oferece alt√≠ssima precis√£o. Para a decis√£o gerencial, um modelo de Gradient Boosting bem ajustado pode ser a ferramenta definitiva para criar um score de cr√©dito extremamente acurado, minimizando perdas por aprovar clientes de alto risco."
                },
                "XGBoost": {
                    "desc": "eXtreme Gradient Boosting √© uma implementa√ß√£o otimizada e de alta performance do Gradient Boosting. Inclui regulariza√ß√£o para evitar overfitting, tratamento de dados faltantes e processamento paralelo, tornando-o mais r√°pido e robusto.",
                    "decision": "√â o padr√£o ouro em muitas competi√ß√µes de dados por um motivo: performance. Na tomada de decis√£o, um modelo XGBoost pode ser a base de um sistema de aprova√ß√£o de cr√©dito automatizado de alta performance, capaz de processar milhares de solicita√ß√µes com grande precis√£o."
                },
                "LightGBM": {
                    "desc": "Light Gradient Boosting Machine √© outra implementa√ß√£o de boosting, focada em velocidade e efici√™ncia de mem√≥ria. Ele cresce as √°rvores 'folha por folha' em vez de 'n√≠vel por n√≠vel', o que o torna extremamente r√°pido em grandes datasets.",
                    "decision": "Sua velocidade o torna ideal para ambientes de produ√ß√£o que exigem decis√µes em tempo real ou retreinamento frequente dos modelos com novos dados. Para a gest√£o, significa ter um sistema de risco que pode ser atualizado diariamente sem comprometer a performance."
                },
                "Rede Neural (MLP)": {
                    "desc": "Multi-layer Perceptron √© um modelo inspirado no c√©rebro humano, com camadas de 'neur√¥nios' interconectados. Ele √© capaz de aprender padr√µes extremamente complexos e n√£o lineares nos dados.",
                    "decision": "Sua for√ßa est√° na capacidade de capturar intera√ß√µes sutis entre as vari√°veis que outros modelos podem n√£o ver. Para a decis√£o, pode revelar perfis de risco n√£o intuitivos, justificando pol√≠ticas de cr√©dito inovadoras e altamente segmentadas."
                }
            }
            
            explanation = model_explanations.get(model_to_inspect, {})
            if explanation:
                with st.expander(f"Entendendo o Modelo: {model_to_inspect}", expanded=True):
                    st.markdown(f"**Como Funciona:** {explanation['desc']}")
                    st.markdown(f"**Relev√¢ncia para a Tomada de Decis√£o:** {explanation['decision']}")

            model_data = baseline_artifacts[model_to_inspect]
            metrics = model_data['metrics']
            
            st.markdown(f"##### M√©tricas de Performance para o Modelo **{model_to_inspect}**")
            
            metric_explanations_detail = {
                "AUC": "Mede a capacidade geral do modelo de distinguir entre bons e maus pagadores. Quanto mais perto de 1.0, melhor.",
                "Acur√°cia": "Percentual geral de acertos. Pode ser enganosa em dados desbalanceados.",
                "Recall": "A m√©trica mais importante para o risco! Dos clientes que realmente eram 'maus', quantos o modelo conseguiu capturar?",
                "Precis√£o": "Dos clientes que o modelo classificou como 'maus', quantos ele acertou?",
                "F1-Score": "Uma m√©dia harm√¥nica entre Precis√£o e Recall. √ötil para um balan√ßo geral."
            }
            
            metric_cols = st.columns(len(metrics))
            for i, (metric_name, metric_value) in enumerate(metrics.items()):
                help_text = metric_explanations_detail.get(metric_name, "")
                metric_cols[i].metric(metric_name, f"{metric_value:.4f}", help=help_text)

            tab_cm, tab_roc, tab_report, tab_importance = st.tabs(["Matriz de Confus√£o", "Curva ROC", "Relat√≥rio Detalhado", "Import√¢ncia de Features"])
            
            with tab_cm:
                cm = model_data['confusion_matrix']
                fig_cm = px.imshow(
                    cm, text_auto=True, aspect="auto",
                    labels=dict(x="Valores Previstos pelo Modelo", y="Valores Reais da Base de Teste"),
                    x=['Bom Risco', 'Mau Risco'], y=['Bom Risco', 'Mau Risco'],
                    title=f"Matriz de Confus√£o para o Modelo: {model_to_inspect}",
                    color_continuous_scale='Blues'
                )
                fig_cm.update_layout(coloraxis_showscale=False)
                st.plotly_chart(fig_cm, use_container_width=True, key=f"plotly_cm_{model_to_inspect}")
                st.warning(f"O modelo falhou em identificar **{cm[1, 0]}** clientes de alto risco (Falsos Negativos), que representam o maior preju√≠zo potencial. Por outro lado, classificou erroneamente **{cm[0, 1]}** bons clientes como de alto risco (Falsos Positivos).")

            with tab_roc:
                render_roc_tab(model_data, model_to_inspect)
            
            with tab_report:
                render_report_tab(model_data)

            with tab_importance:
                render_importance_tab(model_data, model_to_inspect)

@st.cache_resource(show_spinner="Finalizando modelo campe√£o e calculando explica√ß√µes SHAP...")
def finalize_and_explain_model(_baseline_artifacts, _modeling_data, _selection_artifacts):
    """
    Identifica o melhor modelo, gera explica√ß√µes SHAP e garante que o
    √≠ndice do DataFrame de teste seja preservado para refer√™ncia futura.
    """
    best_model_name = max(_baseline_artifacts, key=lambda k: _baseline_artifacts[k]['metrics']['AUC'])
    final_model_pipeline = _baseline_artifacts[best_model_name]['model_object']
    
    if hasattr(final_model_pipeline, 'steps'):
        final_model = final_model_pipeline.steps[-1][1]
    else:
        final_model = final_model_pipeline

    X_train_final = _selection_artifacts['selector_object'].transform(_modeling_data['X_train_resampled'])
    X_test_final = _selection_artifacts['selector_object'].transform(_modeling_data['X_test'])
    
    X_test_df = pd.DataFrame(
        X_test_final, 
        columns=_selection_artifacts['selected_feature_names'],
        index=_modeling_data['y_test'].index
    )
    
    model_type = type(final_model).__name__
    if model_type in ['XGBClassifier', 'LGBMClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'DecisionTreeClassifier']:
        explainer = shap.TreeExplainer(final_model)
    else:
        # Para KernelExplainer, √© importante usar o pipeline completo que inclui pr√©-processamento, se aplic√°vel
        # No entanto, os dados aqui j√° est√£o processados, ent√£o usamos final_model_pipeline.predict_proba
        X_train_summary = shap.sample(X_train_final, 100)
        explainer = shap.KernelExplainer(final_model_pipeline.predict_proba, X_train_summary)
    
    shap_values_obj = explainer(X_test_df)
    
    # Extrai o valor esperado (base value). Para modelos de duas classes, SHAP pode retornar uma lista com dois valores.
    # Queremos o valor base para a classe 1 ('mau risco').
    expected_value = explainer.expected_value
    if isinstance(expected_value, list):
        expected_value = expected_value[1]

    y_proba_test = final_model_pipeline.predict_proba(X_test_df)

    final_artifacts = {
        'model_name': best_model_name,
        'model_object': final_model_pipeline,
        'X_test_df': X_test_df,
        'y_test': _modeling_data['y_test'],
        'y_proba_test': y_proba_test,
        # CORRE√á√ÉO: Padronizando a chave para 'shap_values' e garantindo que seja o objeto de explica√ß√£o para a classe de MAU RISCO.
        'shap_values': shap_values_obj[:,:,1],
        'expected_value': expected_value
    }
    return final_artifacts

def render_final_model_analysis_module(baseline_artifacts, modeling_data, selection_artifacts):
    """
    Renderiza a UI para a sele√ß√£o do modelo campe√£o e a an√°lise de trade-off
    entre Precis√£o e Recall, um passo crucial para a decis√£o de neg√≥cio.
    """
    with st.container(border=True):
        st.subheader("Etapa 5: Sele√ß√£o do Modelo Campe√£o e Gera√ß√£o de Explica√ß√µes (XAI)")
        st.markdown("""
        **O Qu√™?** Com base no leaderboard, elegemos o modelo com maior **AUC** como nosso campe√£o. Agora, vamos submet√™-lo ao passo mais importante: a **gera√ß√£o de explica√ß√µes com SHAP**. Isso nos permitir√° entender *por que* o modelo toma certas decis√µes, abrindo a caixa-preta da IA.

        **Por qu√™?** Um bom modelo n√£o √© apenas preciso, ele √© **confi√°vel e transparente**. A explicabilidade √© fundamental para que o time de neg√≥cios confie nas previs√µes e para que possamos criar pol√≠ticas de cr√©dito justas e eficazes. Esta etapa √© o pr√©-requisito para a an√°lise de decis√£o gerencial.
        """)
        
        best_model_name = max(
            baseline_artifacts, 
            key=lambda k: baseline_artifacts[k]['metrics']['AUC']
        )
        st.success(f"O modelo com melhor performance (maior AUC) no leaderboard √© o **{best_model_name}**. Ele ser√° promovido para a an√°lise de explicabilidade.", icon="üèÜ")

        if st.button("Analisar Modelo Campe√£o e Gerar Explica√ß√µes SHAP", key="final_model_button", type='primary'):
            with st.spinner("Executando an√°lise de explicabilidade com SHAP... Este processo pode levar alguns minutos."):
                final_artifacts = finalize_and_explain_model(baseline_artifacts, modeling_data, selection_artifacts)
                if final_artifacts:
                    st.session_state.artifacts['final_artifacts'] = final_artifacts
                    st.session_state.app_stage = 'final_model_selected'
                    st.success("An√°lise do modelo final e explica√ß√µes SHAP geradas com sucesso!")
                    time.sleep(2) # Pausa para o usu√°rio ver a mensagem de sucesso
                    st.rerun()
                else:
                    st.error("Falha ao gerar as explica√ß√µes do modelo.")

    if 'final_artifacts' in st.session_state.get('artifacts', {}):
        st.markdown("---")
        st.info("Modelo campe√£o analisado! Agora voc√™ pode prosseguir para a p√°gina de **Decis√£o Gerencial e N√£o Supervisionada** para os insights finais.", icon="üëâ")

def display_advanced_analysis_page():
    """
    Renderiza a p√°gina principal de "Decis√£o Gerencial e N√£o Supervisionada".
    Esta vers√£o coloca a se√ß√£o de Tomada de Decis√£o em primeiro lugar,
    seguida pelas abas com as evid√™ncias (SHAP, Clusters).
    """
    st.header("Decis√£o Gerencial e An√°lise Avan√ßada üß†", divider='rainbow')

    if 'final_artifacts' not in st.session_state.get('artifacts', {}):
        st.error("‚ö†Ô∏è An√°lise Avan√ßada Bloqueada", icon="üö®")
        st.warning("Para habilitar esta p√°gina, execute o pipeline completo na p√°gina 'Modelagem Supervisionada' e clique em 'Analisar Modelo Campe√£o'.")
        return
        
    final_artifacts = st.session_state.artifacts['final_artifacts']
    
    # Adicionando a explica√ß√£o sobre a defini√ß√£o de risco
    st.info("""
    **Defini√ß√£o de Risco Utilizada no Projeto:** Conforme os crit√©rios de neg√≥cio descritos no enunciado da prova, um cliente √© definido como:
    - **Mau Pagador (`bad`):** Deixa de pagar a fatura por mais de 90 dias consecutivos.
    - **Bom Pagador (`good`):** Todos os demais clientes.
    O objetivo dos modelos √© prever esta classifica√ß√£o pr√©-definida.
    """, icon="‚ÑπÔ∏è")
    st.markdown("---")
    
    # Se√ß√£o de Tomada de Decis√£o (Item I.d da Prova)
    with st.container(border=True):
        st.subheader("‚≠ê Tomada de Decis√£o e Aplica√ß√£o Gerencial (An√°lise Cr√≠tica)")
    st.error("Esta se√ß√£o sintetiza os resultados e apresenta recomenda√ß√µes acion√°veis para o neg√≥cio.", icon="‚ö†Ô∏è")

    st.markdown("#### Perfil do Cliente de Baixo Risco (Bom Pagador)")
    st.markdown("""
    Antes de focar nos riscos, √© crucial entender o que caracteriza um **bom cliente** aos olhos do modelo. A an√°lise de explicabilidade (SHAP) revela que os fatores que mais consistentemente **diminuem** a probabilidade de risco (`bad`) s√£o:

    - **`checking_status` (Conta Corrente):** Ter uma conta corrente estabelecida, especialmente com saldo positivo (`> 200 DM`), √© o mais forte indicador de estabilidade financeira e baixo risco.
    - **`credit_history` (Hist√≥rico de Cr√©dito):** Clientes com hist√≥rico de pagamentos em dia (`all paid`) ou que quitaram cr√©ditos anteriores na institui√ß√£o (`existing paid`) s√£o vistos como altamente confi√°veis.
    - **`purpose` (Prop√≥sito do Cr√©dito):** Solicita√ß√µes para 'car (new)' e 'education' tendem a ter menor risco associado.
    - **`savings_status` (Poupan√ßa):** A presen√ßa de uma conta poupan√ßa, mesmo com valores baixos, √© um fator de prote√ß√£o.

    **Insight:** O cliente ideal para expans√£o da base n√£o √© apenas jovem ou de classe m√©dia, mas aquele que j√° demonstra um m√≠nimo de organiza√ß√£o financeira, como manter uma conta corrente ativa e um hist√≥rico de pagamentos limpo.
    """)

    st.markdown("---")

    st.markdown("#### Recomenda√ß√µes Estrat√©gicas para a √Årea de Cr√©dito")
    st.markdown("""
    Com base nas an√°lises preditivas e de explicabilidade, formulamos as seguintes recomenda√ß√µes para apoiar a expans√£o da base de clientes de forma sustent√°vel:
    """)

    st.markdown("##### 1. Pol√≠ticas de Cr√©dito Adaptativas por Segmento de Risco")
    st.markdown("""
    - **Recomenda√ß√£o:** Abandonar uma pol√≠tica √∫nica ("one-size-fits-all") e implementar regras de neg√≥cio distintas para diferentes perfis de risco identificados pelo modelo.
    - **A√ß√£o Pr√°tica:**
        - **Perfil de Alto Risco:** Para clientes com m√∫ltiplos fatores de risco (ex: sem conta corrente, hist√≥rico problem√°tico, prazos longos), a aprova√ß√£o autom√°tica deve ser bloqueada, exigindo uma **an√°lise manual criteriosa**. Caso aprovado, aplicar **limites de cr√©dito iniciais mais baixos** e taxas de juros ajustadas ao risco.
        - **Perfil de Risco Moderado:** Para clientes com um perfil misto, pode-se aprovar com um limite padr√£o, mas inclu√≠-los em um programa de **monitoramento refor√ßado** nos primeiros 6 meses.
    """)

    st.markdown("##### 2. Desenvolvimento de Produtos para Expans√£o Segura da Base")
    st.markdown("""
    - **Recomenda√ß√£o:** A empresa deseja atrair jovens adultos, que podem n√£o ter um hist√≥rico de cr√©dito robusto. O modelo mostra que `duration` e `credit_amount` s√£o fatores de risco importantes. Portanto, a estrat√©gia de expans√£o deve ser feita com produtos de menor risco.
    - **A√ß√£o Pr√°tica:**
        - **Criar "Cart√µes de Cr√©dito de Entrada":** Oferecer cart√µes com limites pr√©-aprovados baixos (ex: R$ 500 a R$ 1.500) para jovens e clientes novos no sistema de cr√©dito. O bom uso deste produto pode habilitar aumentos de limite progressivos.
        - **Focar em Cr√©dito Pessoal de Curto Prazo:** Promover linhas de cr√©dito para fins espec√≠ficos (como 'education' ou 'repairs') com prazos de at√© 12 meses, que apresentam risco menor segundo o modelo.
    """)

    st.markdown("##### 3. Gest√£o Proativa da Carteira de Clientes Atuais")
    st.markdown("""
    - **Recomenda√ß√£o:** Utilizar o modelo de risco n√£o apenas para novas aquisi√ß√µes, mas tamb√©m para monitorar a sa√∫de da carteira de clientes existente.
    - **A√ß√£o Pr√°tica:**
        - **Implementar um Sistema de Alerta Precoce:** Executar o modelo periodicamente sobre a base de clientes. Se a pontua√ß√£o de risco de um cliente aumentar significativamente (devido a mudan√ßas em seu comportamento financeiro externo, se dispon√≠vel), o sistema deve alertar a equipe de relacionamento.
        - **A√ß√µes de Reten√ß√£o e Educa√ß√£o:** Para clientes cujo risco aumenta, a empresa pode agir proativamente, oferecendo **programas de educa√ß√£o financeira, op√ß√µes de renegocia√ß√£o de d√≠vida ou consultoria**, antes que a inadimpl√™ncia ocorra.
    """)

    st.markdown("##### 4. Governan√ßa e Manuten√ß√£o do Modelo Preditivo")
    st.markdown("""
    - **Recomenda√ß√£o:** Um modelo de machine learning n√£o √© est√°tico. Seu desempenho pode degradar com o tempo devido a mudan√ßas no cen√°rio econ√¥mico ou no comportamento dos clientes ("concept drift").
    - **A√ß√£o Pr√°tica:**
        - **Estabelecer um Cronograma de Retreinamento:** Definir uma pol√≠tica para retreinar o modelo a cada 6 ou 12 meses, utilizando novos dados de clientes.
        - **Monitoramento Cont√≠nuo:** Acompanhar as m√©tricas de performance do modelo (como AUC e Recall) em produ√ß√£o para detectar quedas de desempenho e acionar a necessidade de uma revis√£o ou retreinamento antes do prazo.
    """)
    
    st.markdown("---")
    st.subheader("Evid√™ncias de Suporte √† Decis√£o")
    st.markdown("As abas abaixo cont√™m as an√°lises detalhadas que fundamentam as recomenda√ß√µes acima.")

    tab_xai, tab_clusters = st.tabs([
        "ü§ñ An√°lise de Explicabilidade (SHAP)", 
        "üåÄ An√°lise de Clusters (K-Means & DBSCAN)"
    ])
    
    with tab_xai:
        render_global_xai_module(final_artifacts)
        render_local_xai_and_recommendations_module(final_artifacts)
        
    with tab_clusters:
        if st.session_state.data_processed:
            processed_df_for_clustering = st.session_state.processed_df
            render_unsupervised_analysis_module(processed_df_for_clustering)

def render_global_xai_module(final_artifacts):
    """
    Renderiza os gr√°ficos de SHAP para uma an√°lise global, com formata√ß√£o ajustada
    e interpreta√ß√µes detalhadas para o contexto de neg√≥cio.
    """
    with st.container(border=True):
        st.subheader("An√°lise de Explicabilidade Global (SHAP)")
        st.markdown("Aqui, abrimos a 'caixa-preta' do modelo para entender quais fatores ele considera mais importantes em suas decis√µes, de forma geral para todos os clientes do conjunto de teste.")
        
        X_test_df = final_artifacts['X_test_df']
        # CORRE√á√ÉO: Acessando a chave correta 'shap_values'
        shap_values = final_artifacts['shap_values']

        st.markdown("#### Import√¢ncia Geral das Features (SHAP Bar Plot)")
        
        fig_bar, ax_bar = plt.subplots()
        # A fun√ß√£o summary_plot funciona corretamente com o objeto de explica√ß√£o
        shap.summary_plot(shap_values, X_test_df, plot_type="bar", show=False, max_display=15)
        plt.title(f"Import√¢ncia M√©dia das Features (Modelo: {final_artifacts['model_name']})")
        plt.tight_layout()
        st.pyplot(fig_bar)
        plt.close(fig_bar)
        
        st.markdown("""
        **An√°lise do Gr√°fico de Barras:**
        - **O que ele mostra?** O gr√°fico acima ranqueia as vari√°veis pela sua **influ√™ncia m√©dia absoluta** nas previs√µes. Features no topo s√£o as que mais pesaram para o modelo tomar uma decis√£o, independentemente se foi para 'bom' ou 'mau' risco.
        - **Insight Gerencial:** Fica claro que `checking_status` (status da conta corrente), `duration` (dura√ß√£o do empr√©stimo) e `credit_history` (hist√≥rico de cr√©dito) s√£o os pilares da decis√£o do modelo. Isso significa que, para uma an√°lise de cr√©dito r√°pida e eficaz, estas s√£o as tr√™s informa√ß√µes mais valiosas a serem coletadas e validadas sobre um cliente.
        """)
        
        st.markdown("---")
        
        st.markdown("#### Impacto e Distribui√ß√£o das Features (SHAP Beeswarm Plot)")
        
        fig_beeswarm, ax_beeswarm = plt.subplots()
        shap.summary_plot(shap_values, X_test_df, plot_type='dot', show=False, max_display=15)
        plt.title("Impacto de Cada Feature no Risco de Cr√©dito")
        plt.tight_layout()
        st.pyplot(fig_beeswarm)
        plt.close(fig_beeswarm)

        st.markdown("""
        **An√°lise Detalhada do Gr√°fico de Dispers√£o:**
        - **O que ele mostra?** Este gr√°fico √© mais poderoso, pois mostra a **dire√ß√£o do impacto**. Cada ponto √© um cliente para uma dada feature. Pontos √† direita do eixo zero aumentam o risco de inadimpl√™ncia; pontos √† esquerda diminuem. A cor indica o valor da feature (Vermelho = Alto, Azul = Baixo).
                
        **Insights Gerenciais:**
        - **`checking_status`:** Pontos vermelhos (status 'no checking' ou '...<0 DM') est√£o quase todos √† direita, com altos valores SHAP. Isso **confirma** que ter uma conta corrente ruim ou inexistente √© o maior indicador de risco.
        - **`duration`:** A dispers√£o de vermelho para a direita mostra que quanto **maior a dura√ß√£o** do empr√©stimo, **maior o risco** previsto pelo modelo.
        - **`credit_amount`:** Similar √† dura√ß√£o, valores de cr√©dito mais altos (pontos vermelhos) tendem a aumentar o risco.
        - **`age`:** A tend√™ncia aqui √© sutil, mas parece que idades mais baixas (pontos azuis) est√£o levemente associadas a um maior risco (valores SHAP positivos).
        """)

def render_local_xai_and_recommendations_module(final_artifacts):
    with st.container(border=True):
        st.subheader("An√°lise de Previs√£o Individual (Por que este cliente?)")
        st.markdown("""
        Se a an√°lise global mostra 'o que' o modelo valoriza, a an√°lise local mostra o 'porqu√™' para um cliente espec√≠fico.
        Selecione um cliente do conjunto de teste abaixo para ver um **Laudo de Risco Detalhado**, que explica como suas caracter√≠sticas
        o levaram da linha de base do modelo para sua pontua√ß√£o final de risco.
        """)

        y_test = final_artifacts['y_test']
        y_proba = final_artifacts['y_proba_test'][:, 1]
        X_test_df = final_artifacts['X_test_df']
        raw_data_test = st.session_state.artifacts['modeling_data']['X_test_raw']

        info_df = pd.DataFrame({
            'Cr√©dito': raw_data_test['credit_amount'],
            'Dura√ß√£o': raw_data_test['duration'],
            'Prop√≥sito': raw_data_test['purpose'],
            'Prob_Risco (%)': y_proba * 100
        }, index=y_test.index)

        bad_risk_df = info_df[y_test == 1].sort_index()
        good_risk_df = info_df[y_test == 0].sort_index()

        bad_risk_clients = {
            f"Cliente {idx} | Risco Previsto: {row['Prob_Risco (%)']:.1f}% (Cr√©dito: R${int(row['Cr√©dito'])}, Prazo: {int(row['Dura√ß√£o'])} meses)": idx
            for idx, row in bad_risk_df.iterrows()
        }

        good_risk_clients = {
            f"Cliente {idx} | Risco Previsto: {row['Prob_Risco (%)']:.1f}% (Cr√©dito: R${int(row['Cr√©dito'])}, Prazo: {int(row['Dura√ß√£o'])} meses)": idx
            for idx, row in good_risk_df.iterrows()
        }
        
        tab_bad, tab_good = st.tabs(["Analisar um Cliente de Mau Risco (Real)", "Analisar um Cliente de Bom Risco (Real)"])

        def generate_waterfall_plot(selected_client_label, client_dict):
            if not selected_client_label:
                st.info("Por favor, selecione um cliente da lista acima para ver a an√°lise.")
                return

            original_index = client_dict[selected_client_label]
            try:
                row_position = X_test_df.index.get_loc(original_index)
                shap_values_for_instance = final_artifacts['shap_values'][row_position]

                shap_explanation_object = shap.Explanation(
                    values=shap_values_for_instance,
                    base_values=final_artifacts['expected_value'],
                    data=X_test_df.iloc[row_position],
                    feature_names=X_test_df.columns.tolist()
                )
                
                fig, ax = plt.subplots()
                shap.waterfall_plot(shap_explanation_object, max_display=15, show=False)
                st.pyplot(fig)
                plt.close(fig)

                st.markdown("---")
                st.subheader("An√°lise Detalhada do Laudo de Risco Individual")
                
                base_value = shap_explanation_object.base_values
                final_score = base_value + shap_explanation_object.values.sum()

                st.markdown("""
                        **O gr√°fico de cascata acima detalha como o modelo construiu sua previs√£o para este cliente. A an√°lise funciona da seguinte forma:**
                        1.  **Ponto de Partida (Valor Base `E[f(X)]`):** O modelo come√ßa com a pontua√ß√£o de risco m√©dia de todos os clientes, que √© **{base_value:.2f}**. Este √© o risco esperado antes de conhecer qualquer caracter√≠stica individual.
                        2.  **Constru√ß√£o do Risco:** As setas no gr√°fico mostram como cada caracter√≠stica do cliente empurrou a previs√£o para longe do valor base. Setas vermelhas (‚Üë) aumentam o risco; setas azuis (‚Üì) diminuem.
                        3.  **Previs√£o Final (`f(x)`):** A soma de todos esses impactos resulta na pontua√ß√£o de risco final do cliente, que √© **{final_score:.2f}**. Valores acima do base indicam um risco maior que a m√©dia.
                        """.format(base_value=base_value, final_score=final_score))

                shap_df = pd.DataFrame({
                    'feature': shap_explanation_object.feature_names,
                    'feature_value': shap_explanation_object.data,
                    'shap_value': shap_explanation_object.values
                })
                
                risk_factors = shap_df[shap_df['shap_value'] > 0].sort_values(by='shap_value', ascending=False)
                protective_factors = shap_df[shap_df['shap_value'] < 0].sort_values(by='shap_value', ascending=True)

                is_high_risk = final_artifacts['y_test'].loc[original_index] == 1

                if is_high_risk:
                    st.error("#### Diagn√≥stico: Perfil de Alto Risco", icon="üö®")
                    st.markdown("""
                    A pontua√ß√£o final do cliente est√° significativamente acima do valor base, indicando que o modelo identificou um **conjunto de fatores de risco que superam os fatores de prote√ß√£o**. A seguir, detalhamos a narrativa de risco constru√≠da pelo modelo:
                    """)
                    
                    main_risk_factor = risk_factors.iloc[0]
                    st.markdown(f"""
                    - **Fator Dominante de Risco:** O principal impulsionador da previs√£o de risco foi **`{main_risk_factor['feature']}`**. O valor desta caracter√≠stica (`{main_risk_factor['feature_value']}`) √© fortemente associado a inadimpl√™ncia, de acordo com o padr√£o aprendido pelo modelo.
                    - **Combina√ß√£o de Riscos:** Al√©m do fator principal, outras caracter√≠sticas como `{risk_factors.iloc[1]['feature']}` e `{risk_factors.iloc[2]['feature']}` contribu√≠ram para elevar a pontua√ß√£o. √â a **combina√ß√£o** desses m√∫ltiplos sinais de alerta que solidifica a previs√£o de alto risco.
                    - **Fatores de Prote√ß√£o Insuficientes:** Embora o cliente possa ter caracter√≠sticas positivas (como as listadas na se√ß√£o 'Fatores de Prote√ß√£o'), o impacto delas n√£o foi suficiente para compensar o peso dos indicadores negativos.
                    """)
                else:
                    st.success("#### Diagn√≥stico: Perfil de Baixo Risco", icon="‚úÖ")
                    st.markdown("""
                    A pontua√ß√£o final do cliente est√° consideravelmente abaixo do valor base. Isso significa que o modelo identificou um **perfil com fortes indicadores de prote√ß√£o, que anulam eventuais fatores de risco**. A narrativa de confian√ßa do modelo √© a seguinte:
                    """)
                    
                    main_protective_factor = protective_factors.iloc[0]
                    st.markdown(f"""
                    - **Fator Dominante de Prote√ß√£o:** A caracter√≠stica mais importante que reduziu a previs√£o de risco foi **`{main_protective_factor['feature']}`**. O valor apresentado pelo cliente (`{main_protective_factor['feature_value']}`) √© um forte indicador de bom comportamento de pagamento.
                    - **Perfil S√≥lido:** Outros fatores, como `{protective_factors.iloc[1]['feature']}` e `{protective_factors.iloc[2]['feature']}`, tamb√©m contribu√≠ram positivamente, refor√ßando a previs√£o de baixo risco.
                    - **Riscos Mitigados:** Mesmo que o cliente tenha alguma caracter√≠stica que isoladamente poderia ser um risco (ex: alto valor de cr√©dito), o conjunto de seus outros atributos positivos foi forte o suficiente para que o modelo o classificasse como um bom pagador.
                    """)

            except (KeyError, IndexError) as e:
                    st.error(f"N√£o foi poss√≠vel localizar ou processar os dados do cliente com √≠ndice {original_index}. Erro: {e}")

        with tab_bad:
            st.markdown("**Selecione um cliente que o banco de dados identificou como `Mau Risco`:**")
            selected_bad_label = st.selectbox("Selecione o Cliente:", options=list(bad_risk_clients.keys()), key="select_bad", index=None, placeholder="Escolha um cliente para analisar...")
            generate_waterfall_plot(selected_bad_label, bad_risk_clients)

        with tab_good:
            st.markdown("**Selecione um cliente que o banco de dados identificou como `Bom Risco`:**")
            selected_good_label = st.selectbox("Selecione o Cliente:", options=list(good_risk_clients.keys()), key="select_good", index=None, placeholder="Escolha um cliente para analisar...")
            generate_waterfall_plot(selected_good_label, good_risk_clients)

    with st.container(border=True):
        st.subheader("‚≠ê Tomada de Decis√£o e Aplica√ß√£o Gerencial (An√°lise Cr√≠tica)")
        st.error("Esta se√ß√£o √© o foco principal da avalia√ß√£o", icon="‚ö†Ô∏è")
        st.markdown("""
        Com base em todas as an√°lises realizadas, especialmente nos insights dos gr√°ficos SHAP (global e local),
        formulamos as seguintes recomenda√ß√µes para a √°rea de cr√©dito da institui√ß√£o financeira:

        #### 1. Fatores Cr√≠ticos para Previs√£o de Risco:
        A an√°lise de explicabilidade global (SHAP Bar e Beeswarm Plots) revelou que os seguintes fatores s√£o os mais determinantes para o modelo prever um cliente como de **'Mau Risco'**:
        - **`checking_status` (Status da Conta Corrente):** Clientes com status 'no checking' ou valores baixos consistentemente apresentam altos SHAP values positivos, indicando ser o principal fator de risco. A aus√™ncia de uma conta corrente ou uma conta com poucos recursos √© um forte sinalizador de instabilidade financeira.
        - **`duration` (Dura√ß√£o do Empr√©stimo em Meses):** Prazos de pagamento mais longos aumentam significativamente o risco percebido pelo modelo. Empr√©stimos de longo prazo exp√µem a institui√ß√£o a incertezas por mais tempo.
        - **`credit_history` (Hist√≥rico de Cr√©dito):** Hist√≥ricos de 'critical account/other credits existing' ou 'delay in paying off' s√£o penalizados fortemente pelo modelo, o que √© esperado e valida a l√≥gica do algoritmo.
        - **`credit_amount` (Valor do Cr√©dito):** Valores de empr√©stimo mais elevados, especialmente quando combinados com longas dura√ß√µes, tamb√©m contribuem para um maior risco.

        #### 2. Recomenda√ß√µes Estrat√©gicas para a √Årea de Cr√©dito:
        Com base nestes fatores cr√≠ticos, sugerem-se as seguintes a√ß√µes gerenciais:

        - **Pol√≠tica de Cr√©dito Mais Conservadora para Perfis de Alto Risco:**
          - **Recomenda√ß√£o:** Clientes que se enquadram no perfil de **"sem conta corrente ou com status prec√°rio", "hist√≥rico de pagamentos cr√≠tico" e que solicitam "empr√©stimos de longo prazo"** devem passar por uma an√°lise de cr√©dito mais rigorosa.
          - **A√ß√£o Pr√°tica:** Para estes perfis, a empresa pode implementar limites de cr√©dito iniciais mais baixos, exigir garantias adicionais ou oferecer produtos com taxas de juros ajustadas ao risco. A aprova√ß√£o autom√°tica para esses segmentos deve ser desativada, exigindo uma revis√£o manual.

        - **Desenvolvimento de Produtos de Curto Prazo e Menor Valor:**
          - **Recomenda√ß√£o:** Dado que a dura√ß√£o e o valor do cr√©dito s√£o fatores de risco importantes, a empresa pode focar em expandir seu portf√≥lio de produtos de cr√©dito de curto prazo e menor valor.
          - **A√ß√£o Pr√°tica:** Criar e promover campanhas de marketing para linhas de cr√©dito de at√© 12 meses e valores mais baixos, que podem atrair clientes com menor risco percebido e servir como porta de entrada para um relacionamento de longo prazo.

        - **Monitoramento Refor√ßado e A√ß√µes de Relacionamento Proativo:**
          - **Recomenda√ß√£o:** O modelo pode ser usado n√£o apenas na aprova√ß√£o, mas tamb√©m para monitorar a carteira de clientes existente. Clientes que, mesmo aprovados, possu√≠am caracter√≠sticas de risco lim√≠trofes devem ser monitorados.
          - **A√ß√£o Pr√°tica:** Implementar um sistema de alerta que notifique o time de relacionamento quando um cliente do perfil de risco intermedi√°rio come√ßar a apresentar comportamentos preocupantes (ex: atrasos em outras contas). A√ß√µes proativas, como oferta de renegocia√ß√£o ou educa√ß√£o financeira, podem ser tomadas antes que a inadimpl√™ncia ocorra.
        """)

@st.cache_data(show_spinner="Executando clusteriza√ß√£o com K-Means...")
def run_kmeans_clustering(_df):
    """
    Executa a clusteriza√ß√£o com o algoritmo K-Means.
    Primeiro, utiliza o "M√©todo do Cotovelo" (Elbow Method) para ajudar a
    identificar um n√∫mero 'k' √≥timo de clusters. Em seguida, aplica o K-Means
    com o 'k' escolhido e retorna os resultados.
    """
    numeric_df = _df.select_dtypes(include=np.number).drop(columns=[ProjectConfig.TARGET_VARIABLE], errors='ignore')
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(numeric_df)

    inertia_values = []
    k_range = range(2, 11)
    for k in k_range:
        kmeans = KMeans(n_clusters=k, init='k-means++', random_state=ProjectConfig.RANDOM_STATE_SEED, n_init=10)
        kmeans.fit(scaled_features)
        inertia_values.append(kmeans.inertia_)
    
    optimal_k = 4 # Definido com base na an√°lise do cotovelo
    final_kmeans = KMeans(n_clusters=optimal_k, init='k-means++', random_state=ProjectConfig.RANDOM_STATE_SEED, n_init=10)
    cluster_labels = final_kmeans.fit_predict(scaled_features)
    
    df_clustered = _df.copy()
    df_clustered['cluster'] = cluster_labels
    silhouette = silhouette_score(scaled_features, cluster_labels)
    
    cluster_artifacts = {
        'k_range': k_range, 'inertia_values': inertia_values,
        'optimal_k': optimal_k, 'silhouette_score': silhouette,
        'df_clustered': df_clustered, 'kmeans_model': final_kmeans,
        'scaled_features': scaled_features
    }
    return cluster_artifacts

def render_kmeans_module(cluster_artifacts):
    """
    Renderiza a aba com os resultados da clusteriza√ß√£o K-Means.
    """
    st.subheader("Segmenta√ß√£o de Clientes com K-Means")
    st.markdown("O K-Means particiona os dados em 'K' clusters distintos, onde cada cliente pertence ao grupo com a m√©dia (centroide) mais pr√≥xima.")

    st.markdown("#### Encontrando o N√∫mero Ideal de Clusters (M√©todo do Cotovelo)")
    st.markdown("O gr√°fico abaixo mostra a 'in√©rcia' (soma das dist√¢ncias quadradas). O 'cotovelo', ponto onde a queda na in√©rcia se torna menos pronunciada, sugere um n√∫mero √≥timo de clusters. Para este caso, **K=4** parece um bom equil√≠brio.")
    fig_elbow = go.Figure(data=go.Scatter(x=list(cluster_artifacts['k_range']), y=cluster_artifacts['inertia_values'], mode='lines+markers'))
    fig_elbow.update_layout(title='M√©todo do Cotovelo para Sele√ß√£o de K', xaxis_title='N√∫mero de Clusters (K)', yaxis_title='In√©rcia')
    st.plotly_chart(fig_elbow, use_container_width=True)

    st.markdown("#### Visualiza√ß√£o e An√°lise dos Perfis dos Clusters")
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("**Visualiza√ß√£o dos Clusters (via PCA):**")
        df_clustered = cluster_artifacts['df_clustered']
        pca_result, _ = get_pca_projection(df_clustered.drop(columns=['cluster']), ProjectConfig.TARGET_VARIABLE)
        pca_result['cluster'] = df_clustered['cluster'].values
        fig_pca_cluster = px.scatter(
            pca_result, x='PC1', y='PC2', color='cluster',
            title='Visualiza√ß√£o dos Clusters de Clientes', category_orders={"cluster": sorted(pca_result['cluster'].unique())}
        )
        st.plotly_chart(fig_pca_cluster, use_container_width=True)
    with col2:
        st.markdown("**An√°lise Cruzada com Risco:**")
        risk_by_cluster = df_clustered.groupby('cluster')[ProjectConfig.TARGET_VARIABLE].mean().reset_index()
        risk_by_cluster['class'] = risk_by_cluster['class'] * 100
        fig_risk_bar = px.bar(
            risk_by_cluster, x='cluster', y='class',
            title='Propor√ß√£o de "Mau Risco" por Cluster', text_auto='.2f'
        )
        fig_risk_bar.update_yaxes(title_text='Mau Risco (%)')
        fig_risk_bar.update_traces(marker_color=ProjectConfig.SECONDARY_COLOR)
        st.plotly_chart(fig_risk_bar, use_container_width=True)
        st.metric("Score de Silhueta para K=4", f"{cluster_artifacts['silhouette_score']:.3f}", help="Mede qu√£o bem definidos s√£o os clusters. Valores pr√≥ximos de 1 s√£o melhores.")

    st.markdown("Analisando as m√©dias das principais vari√°veis por cluster, podemos interpretar os perfis:")
    with st.expander("Ver Perfil Detalhado (M√©dias) de Cada Cluster"):
        cluster_profile = df_clustered.groupby('cluster').mean(numeric_only=True)
        st.dataframe(cluster_profile.style.background_gradient(cmap='Blues'), use_container_width=True)

@st.cache_data(show_spinner="Executando detec√ß√£o de outliers com DBSCAN...")
def run_dbscan_outlier_detection(scaled_features):
    """
    Executa o algoritmo DBSCAN para identificar outliers (ru√≠do) nos dados.
    DBSCAN agrupa pontos com base em densidade e √© eficaz para encontrar
    observa√ß√µes que n√£o pertencem a nenhum cluster denso.
    """
    # A escolha de eps e min_samples √© crucial. Estes valores foram ajustados
    # empiricamente para este dataset.
    dbscan = DBSCAN(eps=2.0, min_samples=10, n_jobs=-1)
    outlier_labels = dbscan.fit_predict(scaled_features)
    
    outliers_count = np.sum(outlier_labels == -1)
    outliers_percentage = (outliers_count / len(outlier_labels)) * 100
    
    dbscan_artifacts = {
        'outlier_labels': outlier_labels,
        'outliers_count': outliers_count,
        'outliers_percentage': outliers_percentage
    }
    return dbscan_artifacts

def render_dbscan_module(dbscan_artifacts, df_with_class):
    """
    Renderiza a aba com os resultados da detec√ß√£o de outliers com DBSCAN.
    """
    st.subheader("Detec√ß√£o de Outliers com DBSCAN")
    st.markdown("""
    **O Qu√™?** Utilizamos o DBSCAN para identificar **outliers**, clientes com perfis t√£o at√≠picos que n√£o se encaixam em nenhum grupo coeso. O DBSCAN √© ideal para encontrar "pontos fora da curva".

    **Por qu√™?** Outliers podem representar um **risco oculto** (fraude, comportamento err√°tico) ou uma **oportunidade √∫nica** (um nicho de mercado). A an√°lise abaixo investiga a rela√ß√£o entre ser um outlier e o risco de inadimpl√™ncia.
    """)

    col1, col2 = st.columns(2)
    col1.metric("Clientes At√≠picos (Outliers) Identificados", f"{dbscan_artifacts['outliers_count']}")
    col2.metric("Percentual de Outliers na Base", f"{dbscan_artifacts['outliers_percentage']:.2f}%")

    st.markdown("#### An√°lise Cruzada: Risco de Cr√©dito dos Outliers")
    st.markdown("**Existe rela√ß√£o entre os outliers detectados e o risco de inadimpl√™ncia?**")

    df_with_outliers = df_with_class.copy()
    df_with_outliers['outlier_flag'] = ['Outlier' if label == -1 else 'Comum' for label in dbscan_artifacts['outlier_labels']]
    
    risk_in_outliers = df_with_outliers[df_with_outliers['outlier_flag'] == 'Outlier'][ProjectConfig.TARGET_VARIABLE].mean() * 100
    risk_in_core = df_with_outliers[df_with_outliers['outlier_flag'] == 'Comum'][ProjectConfig.TARGET_VARIABLE].mean() * 100
    
    risk_comparison_df = pd.DataFrame({
        'Grupo de Cliente': ['Outliers', 'Clientes Comuns'],
        'Taxa de Inadimpl√™ncia (%)': [risk_in_outliers, risk_in_core]
    }).set_index('Grupo de Cliente')

    fig_risk_comp = px.bar(
        risk_comparison_df, y='Taxa de Inadimpl√™ncia (%)',
        title='Comparativo de Risco: Outliers vs. Clientes Comuns', text_auto='.2f',
        color=risk_comparison_df.index,
        color_discrete_map={'Outliers': ProjectConfig.BAD_RISK_COLOR, 'Clientes Comuns': ProjectConfig.PRIMARY_COLOR}
    )
    st.plotly_chart(fig_risk_comp, use_container_width=True)

    st.success(f"""
    **Conclus√£o da An√°lise:** A taxa de inadimpl√™ncia entre os outliers √© de **{risk_in_outliers:.2f}%**, enquanto no grupo de clientes comuns √© de **{risk_in_core:.2f}%**. 
    Este resultado mostra que os clientes com perfis at√≠picos, identificados pelo DBSCAN, possuem um risco consideravelmente distinto do restante da carteira, justificando uma an√°lise de cr√©dito individualizada e mais cautelosa para esses casos.
    """)

def render_unsupervised_analysis_module(processed_df):
    st.markdown("Nesta se√ß√£o, usamos modelos n√£o supervisionados para descobrir **estruturas e padr√µes ocultos nos dados sem usar a vari√°vel-alvo**.")

    if 'cluster_artifacts' not in st.session_state.artifacts:
        cluster_artifacts = run_kmeans_clustering(processed_df)
        st.session_state.artifacts['cluster_artifacts'] = cluster_artifacts
    else:
        cluster_artifacts = st.session_state.artifacts['cluster_artifacts']

    if 'dbscan_artifacts' not in st.session_state.artifacts:
        dbscan_artifacts = run_dbscan_outlier_detection(cluster_artifacts['scaled_features'])
        st.session_state.artifacts['dbscan_artifacts'] = dbscan_artifacts
    else:
        dbscan_artifacts = st.session_state.artifacts['dbscan_artifacts']

    tab_kmeans, tab_dbscan = st.tabs(["Clusteriza√ß√£o com K-Means", "Detec√ß√£o de Outliers com DBSCAN"])

    with tab_kmeans:
        render_kmeans_module(cluster_artifacts)
    
    with tab_dbscan:
        render_dbscan_module(dbscan_artifacts, cluster_artifacts['df_clustered'])

def display_modeling_page():
    """
    Renderiza a p√°gina principal de Modelagem Supervisionada, orquestrando
    a chamada sequencial dos m√≥dulos de prepara√ß√£o, sele√ß√£o de features,
    treinamento e an√°lise dos modelos.
    """
    st.header("Pipeline de Modelagem Supervisionada ‚öôÔ∏è", divider='rainbow')
    st.markdown("Execute as etapas em sequ√™ncia para treinar, avaliar e selecionar o melhor modelo preditivo.")
    
    if not st.session_state.get('data_processed'):
        st.warning("‚ö†Ô∏è Por favor, processe os dados na p√°gina 'An√°lise e Prepara√ß√£o dos Dados' para habilitar a modelagem.")
        return

    df = st.session_state.processed_df

    render_data_preparation_module(df)
    
    if 'modeling_data' in st.session_state.artifacts:
        render_feature_selection_module(st.session_state.artifacts['modeling_data'])
    
    if 'selection_artifacts' in st.session_state.artifacts:
        render_baseline_modeling_module(
            st.session_state.artifacts['modeling_data'], 
            st.session_state.artifacts['selection_artifacts']
        )
    
    if 'baseline_artifacts' in st.session_state.artifacts:
        render_model_deep_dive_module(st.session_state.artifacts['baseline_artifacts'])
        render_final_model_analysis_module(
            st.session_state.artifacts['baseline_artifacts'], 
            st.session_state.artifacts['modeling_data'], 
            st.session_state.artifacts['selection_artifacts']
        )

@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def display_export_and_docs_page(artifacts):
    st.header("Documenta√ß√£o e Exporta√ß√£o üìÑ", divider='rainbow')
    st.markdown("Esta se√ß√£o centraliza a documenta√ß√£o t√©cnica do projeto e oferece op√ß√µes para exportar os principais dados e resultados gerados durante a an√°lise.")

    doc_tab, export_tab = st.tabs(["üìú Documenta√ß√£o do Projeto", "üíæ Exportar Resultados"])

    with doc_tab:
        st.subheader("Metodologia e Fluxo de Trabalho do Projeto")
        st.image("https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?q=80&w=2070&auto=format&fit=crop", use_container_width=True)

        st.markdown("""
        Esta se√ß√£o detalha o fluxo de trabalho completo, as ferramentas utilizadas e as
        justificativas para as decis√µes t√©cnicas tomadas ao longo do projeto de
        An√°lise de Risco de Cr√©dito.
        """)
        
        with st.expander("I. An√°lise Preditiva com Modelos Supervisionados", expanded=True):
            st.markdown("""
            - **Diagn√≥stico e Balanceamento:** Foi identificada uma propor√ß√£o de 30% de clientes de 'mau risco'. Para mitigar o vi√©s do modelo em favor da classe majorit√°ria, aplicou-se a t√©cnica **SMOTE** no conjunto de treino.
            - **Treinamento de Modelos:** Foram treinados e avaliados 9 algoritmos de classifica√ß√£o, abrangendo modelos baseados em dist√¢ncia, bagging, boosting e uma rede neural.
            - **M√©tricas de Avalia√ß√£o:** Os modelos foram comparados utilizando AUC, Recall, Precis√£o e F1-Score.
            """)
        with st.expander("II. Explicabilidade (XAI) e Decis√£o Gerencial"):
            st.markdown("""
            - **Explicabilidade com SHAP:** Sobre o modelo de melhor performance, foi aplicada a biblioteca **SHAP** para gerar transpar√™ncia e interpretar os resultados.
            - **Tomada de Decis√£o:** Os insights do SHAP foram traduzidos em recomenda√ß√µes estrat√©gicas para o neg√≥cio.
            """)
        with st.expander("III. Modelos N√£o Supervisionados"):
            st.markdown("""
            - **Clusteriza√ß√£o com K-Means:** O algoritmo foi utilizado para segmentar os clientes em clusters distintos.
            - **Detec√ß√£o de Outliers com DBSCAN:** O algoritmo foi aplicado para identificar clientes com perfis at√≠picos.
            """)
        with st.expander("IV. B√¥nus de Inova√ß√£o: Dashboard Interativo"):
            st.markdown("""
            - Toda esta aplica√ß√£o foi constru√≠da como um dashboard interativo usando **Streamlit**, cumprindo o requisito de b√¥nus.
            """)

    with export_tab:
        st.subheader("Exportar Dados e Artefatos da An√°lise")
        st.info("Clique nos bot√µes abaixo para fazer o download dos arquivos em formato CSV. Os bot√µes s√≥ aparecer√£o se os artefatos correspondentes tiverem sido gerados nas etapas anteriores.", icon="üíæ")

        if 'processed_df' in st.session_state and st.session_state.processed_df is not None:
            csv_processed = convert_df_to_csv(st.session_state.processed_df)
            st.download_button(
                label="Baixar Dados Processados",
                data=csv_processed,
                file_name=f"dados_processados_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                key='download-processed'
            )
        
        if 'baseline_artifacts' in artifacts:
            leaderboard_data = [{'Modelo': name, **res['metrics']} for name, res in artifacts['baseline_artifacts'].items()]
            leaderboard_df = pd.DataFrame(leaderboard_data).sort_values(by='AUC', ascending=False)
            csv_leaderboard = convert_df_to_csv(leaderboard_df)
            st.download_button(
                label="Baixar Leaderboard de Modelos",
                data=csv_leaderboard,
                file_name=f"leaderboard_modelos_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                key='download-leaderboard'
            )

        if 'selection_artifacts' in artifacts:
            selected_features_df = pd.DataFrame(artifacts['selection_artifacts']['selected_feature_names'], columns=["Feature Selecionada"])
            csv_features = convert_df_to_csv(selected_features_df)
            st.download_button(
                label="Baixar Lista de Features Selecionadas",
                data=csv_features,
                file_name=f"features_selecionadas_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                key='download-features'
            )

def main():
    """
    Fun√ß√£o principal que controla a navega√ß√£o e a renderiza√ß√£o das p√°ginas
    do aplicativo Streamlit.
    """
    initialize_session_state()
    px.defaults.template = ProjectConfig.get_plotly_template()

    st.sidebar.title("Painel de Controle üéõÔ∏è")
    st.sidebar.markdown("Navegue pelas etapas da an√°lise de risco de cr√©dito.")
    
    page_options = {
        "P√°gina Inicial": "üè†",
        "An√°lise e Prepara√ß√£o dos Dados": "üìä",
        "An√°lise Explorat√≥ria (EDA)": "üîç",
        "Modelagem Supervisionada": "‚öôÔ∏è",
        "Decis√£o Gerencial e N√£o Supervisionada": "üß†",
    }
    
    page_selection = st.sidebar.radio(
        "Menu de Navega√ß√£o:",
        options=page_options.keys(),
        format_func=lambda x: f"{page_options[x]} {x}"
    )
    
    st.sidebar.markdown(
        """
        <div style='text-align: left; font-size: 0.9em;'>
            <strong>Prova Final</strong><br>
            <span>EPR0072 - SISTEMAS DE INFORMA√á√ÉO EM ENGENHARIA DE PRODU√á√ÉO</span><br>
            <span>Prof. Jo√£o Gabriel de Moraes Souza</span><br><br>
            <strong>Desenvolvedor:</strong><br>
            <span>Pedro Richetti Russo</span>
        </div>
        """,
        unsafe_allow_html=True
    )

    if page_selection == "P√°gina Inicial":
        display_home_page()
    elif page_selection == "An√°lise e Prepara√ß√£o dos Dados":
        display_dataset_page()
    elif page_selection == "An√°lise Explorat√≥ria (EDA)":
        display_eda_page()
    elif page_selection == "Modelagem Supervisionada":
        display_modeling_page()
    elif page_selection == "Decis√£o Gerencial e N√£o Supervisionada":
        display_advanced_analysis_page()

if __name__ == "__main__":
    main()